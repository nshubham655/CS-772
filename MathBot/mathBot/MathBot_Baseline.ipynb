{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MathBot_Baseline.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7Zmw815eWlP"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from nltk.corpus import stopwords  \n",
        "from nltk.tokenize import word_tokenize  \n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing import sequence\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "hSm_btAbqk7e",
        "outputId": "34c4e960-44ea-4a66-d7fc-c50f6a864421"
      },
      "source": [
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RK3JI0F54i7",
        "outputId": "e5c05955-f9a5-4c88-a24e-22618ccde8bf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GD0VpAedeWiX"
      },
      "source": [
        "prepared_dataset=pd.read_csv('/content/drive/MyDrive/Math23K_English_with_data_prep.csv')\n",
        "#prepared_dataset.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTW13_AHeWfn"
      },
      "source": [
        "with open('/content/drive/MyDrive/equations_data.json') as f:\n",
        "  prefix_equations_list = json.load(f)\n",
        "#print(len(prefix_equations_list))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4AZLXdTpe2w"
      },
      "source": [
        "prepared_questions=prepared_dataset['prepared_question'].values.tolist()\n",
        "normal_questions=prepared_dataset['segmented_question'].values.tolist()\n",
        "infix_equations=prepared_dataset['equation'].values.tolist()\n",
        "#print(len(infix_equations))\n",
        "answers=prepared_dataset['ans'].values.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKWEvzFRpezo",
        "outputId": "20b6cb14-1a6b-44f5-d1ac-729ca56d51b6"
      },
      "source": [
        "idx_to_remove=[i for i in range(len(prefix_equations_list)) if prefix_equations_list[i]==\"no_prefix\"]\n",
        "prepared_questions=[prepared_questions[i] for i in range(len(prefix_equations_list)) if prefix_equations_list[i] != \"no_prefix\"]\n",
        "normal_questions=[normal_questions[i] for i in range(len(prefix_equations_list)) if prefix_equations_list[i] != \"no_prefix\"]\n",
        "infix_equations=[infix_equations[i] for i in range(len(prefix_equations_list)) if prefix_equations_list[i] != \"no_prefix\"]\n",
        "answers=[answers[i] for i in range(len(prefix_equations_list)) if prefix_equations_list[i] != \"no_prefix\"]\n",
        "prefix_equations_list=[equation for equation in prefix_equations_list if equation != \"no_prefix\"]\n",
        "\n",
        "\n",
        "idx_to_remove_chinnese=[i for i in range(len(infix_equations)) if infix_equations[i]==\"x=80千米/小时\"]\n",
        "print(idx_to_remove_chinnese)\n",
        "if len(idx_to_remove_chinnese) >=1:\n",
        "  prepared_questions.pop(idx_to_remove_chinnese[0])\n",
        "  normal_questions.pop(idx_to_remove_chinnese[0])\n",
        "  infix_equations.pop(idx_to_remove_chinnese[0])\n",
        "  answers.pop(idx_to_remove_chinnese[0])\n",
        "  prefix_equations_list.pop(idx_to_remove_chinnese[0])\n",
        "\n",
        "# print(len(idx_to_remove))\n",
        "# print(idx_to_remove)\n",
        "# print(len(prefix_equations_list))\n",
        "# print(len(prepared_questions))\n",
        "# print(len(normal_questions)) \n",
        "# print(len(infix_equations))\n",
        "# print(len(answers))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[10149]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EB7ewFspew5",
        "outputId": "f095a16a-55d1-4b6d-f6c2-b22158c5ebff"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xh1fzqTFpetq"
      },
      "source": [
        "temp_questions=list()\n",
        "for elem in prepared_questions:\n",
        "  temp_questions.append(word_tokenize(elem))\n",
        "prepared_questions=temp_questions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOG4Fxl7peqZ",
        "outputId": "a5bcb52d-cff4-4cc9-c9c8-c547d8882f83"
      },
      "source": [
        "index_to_word_input=['<pad>','<sseq>','<eseq>']\n",
        "for question in prepared_questions:\n",
        "  for word in question:\n",
        "    if(word not in index_to_word_input):\n",
        "      index_to_word_input.append(word)\n",
        "#print(len(index_to_word_input))\n",
        "#print(index_to_word_input[0])\n",
        "input_vocab_size=len(index_to_word_input)\n",
        "input_vocab_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7807"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJRUctIppenA"
      },
      "source": [
        "word_to_index_input={'<pad>':0,'<sseq>':1,'<eseq>':2}\n",
        "for question in prepared_questions:\n",
        "  for word in question:\n",
        "    if(word not in word_to_index_input.keys()):\n",
        "      idx=index_to_word_input.index(word)\n",
        "      word_to_index_input[word]=idx\n",
        "#print(len(word_to_index_input))\n",
        "#print(word_to_index_input[\"n0\"])\n",
        "#print(word_to_index_input[\"n1\"])\n",
        "#print(word_to_index_input[\"children\"])\n",
        "#print(word_to_index_input['<pad>'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PWDzhGYpejg"
      },
      "source": [
        "index_to_word_output=['<pad>','<sseq>','<eseq>']\n",
        "for equation in prefix_equations_list:\n",
        "  for elem in equation:\n",
        "    if elem not in index_to_word_output:\n",
        "      index_to_word_output.append(elem)\n",
        "# print(len(index_to_word_output))\n",
        "# print(index_to_word_output[0])\n",
        "output_vocab_size=len(index_to_word_output)\n",
        "# print(output_vocab_size)\n",
        "# print(index_to_word_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH-Gg1XZp24R"
      },
      "source": [
        "word_to_index_output={'<pad>':0,'<sseq>':1,'<eseq>':2}\n",
        "for word in index_to_word_output:\n",
        "  if word not in word_to_index_output.keys():\n",
        "    word_to_index_output[word]=index_to_word_output.index(word)\n",
        "# print(len(word_to_index_output))\n",
        "# print(word_to_index_output[\"n0\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yewcLLD2SRYh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzSXbMjkp21R"
      },
      "source": [
        "prepared_questions_temp=list()\n",
        "for question in prepared_questions:\n",
        "  question_temp=[word_to_index_input['<sseq>']]\n",
        "  for word in question:\n",
        "    question_temp.append(word_to_index_input[word])\n",
        "  question_temp.append(word_to_index_input['<eseq>'])\n",
        "  prepared_questions_temp.append(question_temp)\n",
        "# print(prepared_questions[11235])\n",
        "prepared_questions=prepared_questions_temp\n",
        "# print(prepared_questions[11235])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LybTcraeSZTr",
        "outputId": "ff24be5c-8737-4bfc-e40b-e9e43ac5423d"
      },
      "source": [
        "print(prepared_questions[11235])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 3, 15, 159, 44, 361, 22, 23, 47, 3, 48, 49, 30, 3, 15, 47, 3, 52, 49, 57, 35, 23, 54, 105, 190, 186, 47, 3, 48, 49, 18, 36, 37, 23, 25, 361, 59, 3, 75, 56, 41, 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5pgtleDvFQp"
      },
      "source": [
        "prefix_equations_temp=list()\n",
        "for eq in prefix_equations_list:\n",
        "  eq_temp=[word_to_index_output['<sseq>']]\n",
        "  for word in eq:\n",
        "    eq_temp.append(word_to_index_output[word])\n",
        "  eq_temp.append(word_to_index_input['<eseq>'])\n",
        "  prefix_equations_temp.append(eq_temp)\n",
        "# print(prepared_questions[11235])\n",
        "#prepared_questions=prepared_equations_temp\n",
        " #print(prepared_questions[11235])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhxcGJvrSdsa",
        "outputId": "26feb8fb-17fd-4320-fcf3-a8b6db79dbce"
      },
      "source": [
        "prefix_equations_temp[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 3, 4, 5, 6, 7, 2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1BtkS6jp2yL"
      },
      "source": [
        "max_len=max(len(question) for question in prepared_questions)\n",
        "#print(max_len)\n",
        "prepared_questions= sequence.pad_sequences(prepared_questions, maxlen=max_len,padding=\"post\")\n",
        "# print(prepared_questions[2])\n",
        "# print(len(prepared_questions))\n",
        "#reviews.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XyJIF5JwLNk"
      },
      "source": [
        "max_len_output=max(len(eq) for eq in prefix_equations_temp)\n",
        "#print(max_len)\n",
        "prefix_equations_temp= sequence.pad_sequences(prefix_equations_temp, maxlen=max_len_output,padding=\"post\")\n",
        "# print(prepared_questions[2])\n",
        "# print(len(prepared_questions))\n",
        "#reviews.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvrIYvr3p2vS"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset,DataLoader \n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.sampler import WeightedRandomSampler\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKwT4QhJqA5A"
      },
      "source": [
        "prepared_questions_train, prepared_questions_test, prefix_equations_list_train, prefix_equations_list_test = train_test_split(prepared_questions,prefix_equations_temp, train_size=0.9)\n",
        "# print(len(prepared_questions_train))\n",
        "# print(len(prefix_equations_list_train))\n",
        "# print(len(prepared_questions_test))\n",
        "# print(len(prefix_equations_list_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfEkY6azqA1Z"
      },
      "source": [
        "prepared_questions_train, prepared_questions_val, prefix_equations_list_train, prefix_equations_list_val = train_test_split(prepared_questions_train,prefix_equations_list_train, train_size=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24dhqVuzqAyd",
        "outputId": "feb37a86-7a4c-4a5d-e83d-897da05ee761"
      },
      "source": [
        " print(len(prepared_questions_train))\n",
        " print(len(prefix_equations_list_train))\n",
        " print(input_vocab_size , output_vocab_size)\n",
        " max_len\n",
        "# print(len(prepared_questions_val))\n",
        "# print(len(prefix_equations_list_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18212\n",
            "18212\n",
            "7807 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "137"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AY9M9Ya4Rypf",
        "outputId": "215d9602-51e4-4228-c866-e8955635b9e7"
      },
      "source": [
        "prefix_equations_list_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1,  4,  7,  3, 12,  9,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CarQuMredaRa",
        "outputId": "35c8ab76-bdfa-4d66-d90b-a4bc64ffa159"
      },
      "source": [
        "class EncoderLSTM(nn.Module):\n",
        "\n",
        "  def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
        "    super(EncoderLSTM, self).__init__()\n",
        "\n",
        "    # Size of the one hot vectors that will be the input to the encoder\n",
        "    self.input_size = input_size\n",
        "\n",
        "    # Output size of the word embedding NN\n",
        "    self.embedding_size = embedding_size\n",
        "\n",
        "    # Dimension of the NN's inside the lstm cell/ (hs,cs)'s dimension.\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    # Number of layers in the lstm\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    # Regularization parameter\n",
        "    self.dropout = nn.Dropout(p)\n",
        "    self.tag = True\n",
        "\n",
        "    # Shape --------------------> (5376, 300) [input size, embedding dims]\n",
        "    self.embedding = nn.Embedding(self.input_size, self.embedding_size)\n",
        "    \n",
        "    # Shape -----------> (300, 2, 1024) [embedding dims, hidden size, num layers]\n",
        "    self.LSTM = nn.LSTM(self.embedding_size, hidden_size, num_layers, dropout = p)\n",
        "\n",
        "  # Shape of x (26, 32) [Sequence_length, batch_size]\n",
        "  def forward(self, x):\n",
        "\n",
        "    # Shape -----------> (26, 32, 300) [Sequence_length , batch_size , embedding dims]\n",
        "    embedding = self.dropout(self.embedding(x))\n",
        "    \n",
        "    # Shape --> outputs (26, 32, 1024) [Sequence_length , batch_size , hidden_size]\n",
        "    # Shape --> (hs, cs) (2, 32, 1024) , (2, 32, 1024) [num_layers, batch_size size, hidden_size]\n",
        "    outputs, (hidden_state, cell_state) = self.LSTM(embedding)\n",
        "\n",
        "    return hidden_state, cell_state\n",
        "\n",
        "input_size_encoder = input_vocab_size\n",
        "encoder_embedding_size = 300\n",
        "hidden_size = 1024\n",
        "num_layers = 2\n",
        "encoder_dropout = float(0.5)\n",
        "\n",
        "encoder_lstm = EncoderLSTM(input_size_encoder, encoder_embedding_size,\n",
        "                           hidden_size, num_layers, encoder_dropout).to(device)\n",
        "print(encoder_lstm)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EncoderLSTM(\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (embedding): Embedding(7807, 300)\n",
            "  (LSTM): LSTM(300, 1024, num_layers=2, dropout=0.5)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccQC8hltd1iZ",
        "outputId": "70cc1a30-b4fc-4a3c-b5d7-00c60c9a392d"
      },
      "source": [
        "class DecoderLSTM(nn.Module):\n",
        "  def __init__(self, input_size, embedding_size, hidden_size, num_layers, p, output_size):\n",
        "    super(DecoderLSTM, self).__init__()\n",
        "\n",
        "    # Size of the one hot vectors that will be the input to the encoder\n",
        "    self.input_size = input_size\n",
        "\n",
        "    # Output size of the word embedding NN\n",
        "    self.embedding_size = embedding_size\n",
        "\n",
        "    # Dimension of the NN's inside the lstm cell/ (hs,cs)'s dimension.\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    # Number of layers in the lstm\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    # Size of the one hot vectors that will be the output to the encoder (English Vocab Size)\n",
        "    self.output_size = output_size\n",
        "\n",
        "    # Regularization parameter\n",
        "    self.dropout = nn.Dropout(p)\n",
        "    self.tag = True\n",
        "\n",
        "    # Shape --------------------> (5376, 300) [input size, embedding dims]\n",
        "    self.embedding = nn.Embedding(self.input_size, self.embedding_size)\n",
        "\n",
        "    # Shape -----------> (300, 2, 1024) [embedding dims, hidden size, num layers]\n",
        "    self.LSTM = nn.LSTM(self.embedding_size, hidden_size, num_layers, dropout = p)\n",
        "\n",
        "    # Shape -----------> (1024, 4556) [embedding dims, hidden size, num layers]\n",
        "    self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "  # Shape of x (32) [batch_size]\n",
        "  def forward(self, x, hidden_state, cell_state):\n",
        "\n",
        "    # Shape of x (1, 32) [1, batch_size]\n",
        "    x = x.unsqueeze(0)\n",
        "\n",
        "    # Shape -----------> (1, 32, 300) [1, batch_size, embedding dims]\n",
        "    embedding = self.dropout(self.embedding(x))\n",
        "\n",
        "    # Shape --> outputs (1, 32, 1024) [1, batch_size , hidden_size]\n",
        "    # Shape --> (hs, cs) (2, 32, 1024) , (2, 32, 1024) [num_layers, batch_size size, hidden_size] (passing encoder's hs, cs - context vectors)\n",
        "    outputs, (hidden_state, cell_state) = self.LSTM(embedding, (hidden_state, cell_state))\n",
        "\n",
        "    # Shape --> predictions (1, 32, 4556) [ 1, batch_size , output_size]\n",
        "    predictions = self.fc(outputs)\n",
        "\n",
        "    # Shape --> predictions (32, 4556) [batch_size , output_size]\n",
        "    predictions = predictions.squeeze(0)\n",
        "\n",
        "    return predictions, hidden_state, cell_state\n",
        "\n",
        "input_size_decoder = input_vocab_size\n",
        "decoder_embedding_size = 300\n",
        "hidden_size = 1024\n",
        "num_layers = 2\n",
        "decoder_dropout = float(0.5)\n",
        "output_size = output_vocab_size\n",
        "\n",
        "decoder_lstm = DecoderLSTM(input_size_decoder, decoder_embedding_size,\n",
        "                           hidden_size, num_layers, decoder_dropout, output_size).to(device)\n",
        "print(decoder_lstm)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DecoderLSTM(\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (embedding): Embedding(7807, 300)\n",
            "  (LSTM): LSTM(300, 1024, num_layers=2, dropout=0.5)\n",
            "  (fc): Linear(in_features=1024, out_features=32, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEIFBaV7d1fO",
        "outputId": "50c43cd0-77c0-45b1-bd3d-cda8f037375e"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, Encoder_LSTM, Decoder_LSTM):\n",
        "    super(Seq2Seq, self).__init__()\n",
        "    self.Encoder_LSTM = Encoder_LSTM\n",
        "    self.Decoder_LSTM = Decoder_LSTM\n",
        "\n",
        "  def forward(self, source, target, tfr=0.5,mode='train'):\n",
        "    # Shape - Source : (10, 32) [(Sentence length German + some padding), Number of Sentences]\n",
        "    batch_size = source.shape[1]\n",
        "    #print(source.shape , target.shape)\n",
        "    # Shape - Source : (14, 32) [(Sentence length English + some padding), Number of Sentences]ape\n",
        "\n",
        "    # Shape --> (hs, cs) (2, 32, 1024) ,(2, 32, 1024) [num_layers, batch_size size, hidden_size] (contains encoder's hs, cs - context vectors)\n",
        "    hidden_state_encoder, cell_state_encoder = self.Encoder_LSTM(source)\n",
        "\n",
        "  \n",
        "    if mode=='test':\n",
        "      x = torch.tensor([1]*batch_size).to(device) # Trigger token <SOS>\n",
        "      #print(x)\n",
        "      outputs = []\n",
        "      check = torch.tensor([2]*batch_size).to(device)\n",
        "      while ( torch.all(x.eq(check)) == False):\n",
        "         \n",
        "        output, hidden_state_decoder, cell_state_decoder = self.Decoder_LSTM(x, hidden_state_encoder, cell_state_encoder)\n",
        "        outputs.append(output.cpu().detach().numpy())\n",
        "        best_guess = output.argmax(1) # 0th dimension is batch size, 1st dimension is word embedding\n",
        "        x = best_guess \n",
        " \n",
        "      return outputs\n",
        "\n",
        "    \n",
        "    target_len = target.shape[0]\n",
        "    target_vocab_size = output_vocab_size\n",
        "    \n",
        "    # Shape --> outputs (14, 32, 5766) \n",
        "    outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
        "\n",
        "    x = target[0] # Trigger token <SOS>\n",
        "    #print(x)\n",
        "    for i in range(1, target_len):\n",
        "      # Shape --> output (32, 5766) \n",
        "      output, hidden_state_decoder, cell_state_decoder = self.Decoder_LSTM(x, hidden_state_encoder, cell_state_encoder)\n",
        "      outputs[i] = output\n",
        "      best_guess = output.argmax(1) # 0th dimension is batch size, 1st dimension is word embedding\n",
        "      x = target[i] if random.random() < tfr else best_guess # Either pass the next word correctly from the dataset or use the earlier predicted word\n",
        "\n",
        "    # Shape --> outputs (14, 32, 5766) \n",
        "    return outputs\n",
        "    '''\n",
        "    return total_pred\n",
        "    '''\n",
        "model = Seq2Seq(encoder_lstm , decoder_lstm)\n",
        "print(model)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seq2Seq(\n",
            "  (Encoder_LSTM): EncoderLSTM(\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "    (embedding): Embedding(7807, 300)\n",
            "    (LSTM): LSTM(300, 1024, num_layers=2, dropout=0.5)\n",
            "  )\n",
            "  (Decoder_LSTM): DecoderLSTM(\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "    (embedding): Embedding(7807, 300)\n",
            "    (LSTM): LSTM(300, 1024, num_layers=2, dropout=0.5)\n",
            "    (fc): Linear(in_features=1024, out_features=32, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puMcAC14thwB"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters() , lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pr6aTIT30K7"
      },
      "source": [
        "def get_accuracy(y_pred,target):\n",
        "    \n",
        "        y_pred = y_pred.permute(0,2,1)\n",
        "        _, y_pred = torch.max(y_pred, dim = 2)\n",
        "        total_acc =0\n",
        "        for true,pred in zip(target,y_pred):\n",
        "          tp=0\n",
        "          total=0\n",
        "          acc =0\n",
        "          for t,t_h in zip(true,pred):\n",
        "            if(t!=0):\n",
        "              if(t==t_h):\n",
        "                tp+=1\n",
        "            total+=1\n",
        "          acc = tp/total\n",
        "          total_acc += acc\n",
        "\n",
        "        \n",
        "        acc = total_acc / target.shape[0]\n",
        "        acc = acc * 100\n",
        "        return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrBo8wHI6lr2",
        "outputId": "75dd1ed2-c0cb-4d05-c342-98654a4e6839"
      },
      "source": [
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (Encoder_LSTM): EncoderLSTM(\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "    (embedding): Embedding(7807, 300)\n",
              "    (LSTM): LSTM(300, 1024, num_layers=2, dropout=0.5)\n",
              "  )\n",
              "  (Decoder_LSTM): DecoderLSTM(\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "    (embedding): Embedding(7807, 300)\n",
              "    (LSTM): LSTM(300, 1024, num_layers=2, dropout=0.5)\n",
              "    (fc): Linear(in_features=1024, out_features=32, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hhdz7gDC7Xzh",
        "outputId": "6a8d0139-2fa6-4337-bbf7-671eb3d7d9d0"
      },
      "source": [
        "!pip install tqdm\n",
        "from tqdm import trange\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgaqYgGOd1cO",
        "outputId": "b4164f63-95e1-4018-d749-2aca70f00fa8"
      },
      "source": [
        "num_epochs = 100\n",
        "best_loss = 999999\n",
        "best_epoch = -1\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  print(\"Epoch - {} / {}\".format(epoch+1, num_epochs))\n",
        "  epoch_loss = 0.0\n",
        "  batch_idx = 0\n",
        "  total_acc = 0\n",
        "  model.train()\n",
        "\n",
        "  \n",
        "  #pbar = tqdm(total = len(prepared_questions_train)/batch_size)\n",
        "  while (batch_idx+1)*batch_size < len(prepared_questions_train):\n",
        "\n",
        "    start = batch_idx*batch_size\n",
        "\n",
        "    input = torch.tensor(prepared_questions_train[start : start+batch_size]).to(device)\n",
        "    target = torch.tensor(prefix_equations_list_train[start : start+batch_size]).to(device)\n",
        "\n",
        "    # Pass the input and target for model's forward method\n",
        "    output = model(input.transpose(0,1), target.transpose(0,1))\n",
        "\n",
        "    output = output.permute(1,2,0)\n",
        "   \n",
        "    #print(output.shape)\n",
        "    target = torch.LongTensor(target.cpu().detach().numpy()).to(device)\n",
        "    #print(target.shape)    \n",
        "\n",
        "    # Clear the accumulating gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "      acc = get_accuracy(output,target)\n",
        "      total_acc += acc\n",
        "\n",
        "    # Calculate the loss value for every epoch\n",
        "    loss = criterion(output, target)\n",
        "\n",
        "    # Calculate the gradients for weights & biases using back-propagation\n",
        "    loss.backward()\n",
        "\n",
        "    # Clip the gradient value is it exceeds > 1\n",
        "    #torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "\n",
        "    # Update the weights values using the gradients we calculated using bp \n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "    #writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
        "    #print(loss.item(), acc)\n",
        "\n",
        "    batch_idx +=1\n",
        "    \n",
        "    \n",
        "  print(\"Epoch_Loss - {} , accuracy : {}\".format(epoch_loss/batch_idx , total_acc/batch_idx))\n",
        "  print()\n",
        "  \n",
        "  with torch.no_grad():\n",
        "\n",
        "    model.eval()\n",
        "    while (batch_idx+1)*batch_size < len(prepared_questions_test):\n",
        "\n",
        "      start = batch_idx*batch_size\n",
        "\n",
        "      input = torch.tensor(prepared_questions_test[start : start+batch_size]).to(device)\n",
        "      target = torch.tensor(prefix_equations_list_test[start : start+batch_size]).to(device)\n",
        "\n",
        "      # Pass the input and target for model's forward method\n",
        "      output = model(input.transpose(0,1), target.transpose(0,1),mode='test')\n",
        "\n",
        "      output = torch.tensor(output).permute(1,2,0)\n",
        "   \n",
        "      #print(output.shape)\n",
        "      target = torch.LongTensor(target.cpu().detach().numpy()).to(device)\n",
        "      #print(target.shape)    \n",
        "\n",
        "\n",
        "    \n",
        "      acc = get_accuracy(output,target)\n",
        "      total_acc += acc\n",
        "\n",
        "      batch_idx +=1\n",
        "\n",
        "    print(\"Epoch accuracy : {}\".format(total_acc/batch_idx))\n",
        "    print()\n",
        "  \n",
        "print(epoch_loss / len(prefix_equations_list_train))\n",
        "\n",
        "#score = bleu(test_data[1:100], model, german, english, device)\n",
        "#print(f\"Bleu score {score*100:.2f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch - 1 / 100\n",
            "Epoch_Loss - 2.162599009527287 , accuracy : 5.193917867671152\n",
            "\n",
            "Epoch accuracy : 5.193917867671152\n",
            "\n",
            "Epoch - 2 / 100\n",
            "Epoch_Loss - 2.1322308543702246 , accuracy : 5.3565396740910645\n",
            "\n",
            "Epoch accuracy : 5.3565396740910645\n",
            "\n",
            "Epoch - 3 / 100\n",
            "Epoch_Loss - 2.1359360453108667 , accuracy : 5.283609359646256\n",
            "\n",
            "Epoch accuracy : 5.283609359646256\n",
            "\n",
            "Epoch - 4 / 100\n",
            "Epoch_Loss - 2.135104195332863 , accuracy : 5.266080494595487\n",
            "\n",
            "Epoch accuracy : 5.266080494595487\n",
            "\n",
            "Epoch - 5 / 100\n",
            "Epoch_Loss - 2.1735972451492094 , accuracy : 5.217204389125458\n",
            "\n",
            "Epoch accuracy : 5.217204389125458\n",
            "\n",
            "Epoch - 6 / 100\n",
            "Epoch_Loss - 2.1272969010850074 , accuracy : 5.320074516868657\n",
            "\n",
            "Epoch accuracy : 5.320074516868657\n",
            "\n",
            "Epoch - 7 / 100\n",
            "Epoch_Loss - 2.1305168447360185 , accuracy : 5.2839932034064905\n",
            "\n",
            "Epoch accuracy : 5.2839932034064905\n",
            "\n",
            "Epoch - 8 / 100\n",
            "Epoch_Loss - 2.124390931196616 , accuracy : 5.334660579757625\n",
            "\n",
            "Epoch accuracy : 5.334660579757625\n",
            "\n",
            "Epoch - 9 / 100\n",
            "Epoch_Loss - 2.1312956088025805 , accuracy : 5.24343371274157\n",
            "\n",
            "Epoch accuracy : 5.24343371274157\n",
            "\n",
            "Epoch - 10 / 100\n",
            "Epoch_Loss - 2.1276333063421116 , accuracy : 5.299730797576162\n",
            "\n",
            "Epoch accuracy : 5.299730797576162\n",
            "\n",
            "Epoch - 11 / 100\n",
            "Epoch_Loss - 2.121151368382951 , accuracy : 5.3294147150344\n",
            "\n",
            "Epoch accuracy : 5.3294147150344\n",
            "\n",
            "Epoch - 12 / 100\n",
            "Epoch_Loss - 2.1121110731447246 , accuracy : 5.238571691778584\n",
            "\n",
            "Epoch accuracy : 5.238571691778584\n",
            "\n",
            "Epoch - 13 / 100\n",
            "Epoch_Loss - 2.0346033103029493 , accuracy : 5.596442024238463\n",
            "\n",
            "Epoch accuracy : 5.596442024238463\n",
            "\n",
            "Epoch - 14 / 100\n",
            "Epoch_Loss - 1.990108332163851 , accuracy : 5.906715730429095\n",
            "\n",
            "Epoch accuracy : 5.906715730429095\n",
            "\n",
            "Epoch - 15 / 100\n",
            "Epoch_Loss - 1.9756660772041537 , accuracy : 5.925140230920413\n",
            "\n",
            "Epoch accuracy : 5.925140230920413\n",
            "\n",
            "Epoch - 16 / 100\n",
            "Epoch_Loss - 1.9549029116899195 , accuracy : 6.007794587291194\n",
            "\n",
            "Epoch accuracy : 6.007794587291194\n",
            "\n",
            "Epoch - 17 / 100\n",
            "Epoch_Loss - 1.937689143167415 , accuracy : 6.031720848345894\n",
            "\n",
            "Epoch accuracy : 6.031720848345894\n",
            "\n",
            "Epoch - 18 / 100\n",
            "Epoch_Loss - 1.9090067912155473 , accuracy : 6.205218227972494\n",
            "\n",
            "Epoch accuracy : 6.205218227972494\n",
            "\n",
            "Epoch - 19 / 100\n",
            "Epoch_Loss - 1.8778947633756717 , accuracy : 6.493740787749762\n",
            "\n",
            "Epoch accuracy : 6.493740787749762\n",
            "\n",
            "Epoch - 20 / 100\n",
            "Epoch_Loss - 1.85030524159821 , accuracy : 6.697561824434993\n",
            "\n",
            "Epoch accuracy : 6.697561824434993\n",
            "\n",
            "Epoch - 21 / 100\n",
            "Epoch_Loss - 1.8114586161895536 , accuracy : 6.996192269898466\n",
            "\n",
            "Epoch accuracy : 6.996192269898466\n",
            "\n",
            "Epoch - 22 / 100\n",
            "Epoch_Loss - 1.777829431312185 , accuracy : 7.222404192597455\n",
            "\n",
            "Epoch accuracy : 7.222404192597455\n",
            "\n",
            "Epoch - 23 / 100\n",
            "Epoch_Loss - 1.7525875492834708 , accuracy : 7.407544832951205\n",
            "\n",
            "Epoch accuracy : 7.407544832951205\n",
            "\n",
            "Epoch - 24 / 100\n",
            "Epoch_Loss - 1.7150491031122879 , accuracy : 7.6272314117261795\n",
            "\n",
            "Epoch accuracy : 7.6272314117261795\n",
            "\n",
            "Epoch - 25 / 100\n",
            "Epoch_Loss - 1.6638298664294497 , accuracy : 8.01926383884705\n",
            "\n",
            "Epoch accuracy : 8.01926383884705\n",
            "\n",
            "Epoch - 26 / 100\n",
            "Epoch_Loss - 1.6351626876374366 , accuracy : 8.192249426793321\n",
            "\n",
            "Epoch accuracy : 8.192249426793321\n",
            "\n",
            "Epoch - 27 / 100\n",
            "Epoch_Loss - 1.609085306315355 , accuracy : 8.349113576809707\n",
            "\n",
            "Epoch accuracy : 8.349113576809707\n",
            "\n",
            "Epoch - 28 / 100\n",
            "Epoch_Loss - 1.5647988596432645 , accuracy : 8.633925646904695\n",
            "\n",
            "Epoch accuracy : 8.633925646904695\n",
            "\n",
            "Epoch - 29 / 100\n",
            "Epoch_Loss - 1.5454536953442533 , accuracy : 8.744728545692771\n",
            "\n",
            "Epoch accuracy : 8.744728545692771\n",
            "\n",
            "Epoch - 30 / 100\n",
            "Epoch_Loss - 1.5150686695542135 , accuracy : 8.94279192597446\n",
            "\n",
            "Epoch accuracy : 8.94279192597446\n",
            "\n",
            "Epoch - 31 / 100\n",
            "Epoch_Loss - 1.4883465783696779 , accuracy : 9.102854773992807\n",
            "\n",
            "Epoch accuracy : 9.102854773992807\n",
            "\n",
            "Epoch - 32 / 100\n",
            "Epoch_Loss - 1.4706367766353445 , accuracy : 9.19753623485098\n",
            "\n",
            "Epoch accuracy : 9.19753623485098\n",
            "\n",
            "Epoch - 33 / 100\n",
            "Epoch_Loss - 1.4531884999342368 , accuracy : 9.312689362921724\n",
            "\n",
            "Epoch accuracy : 9.312689362921724\n",
            "\n",
            "Epoch - 34 / 100\n",
            "Epoch_Loss - 1.4326349362521105 , accuracy : 9.414663855224385\n",
            "\n",
            "Epoch accuracy : 9.414663855224385\n",
            "\n",
            "Epoch - 35 / 100\n",
            "Epoch_Loss - 1.4055569096350333 , accuracy : 9.59289530789388\n",
            "\n",
            "Epoch accuracy : 9.59289530789388\n",
            "\n",
            "Epoch - 36 / 100\n",
            "Epoch_Loss - 1.390318836964352 , accuracy : 9.646505486406824\n",
            "\n",
            "Epoch accuracy : 9.646505486406824\n",
            "\n",
            "Epoch - 37 / 100\n",
            "Epoch_Loss - 1.380780685115868 , accuracy : 9.70037156075992\n",
            "\n",
            "Epoch accuracy : 9.70037156075992\n",
            "\n",
            "Epoch - 38 / 100\n",
            "Epoch_Loss - 1.3548559202274806 , accuracy : 9.869774606944002\n",
            "\n",
            "Epoch accuracy : 9.869774606944002\n",
            "\n",
            "Epoch - 39 / 100\n",
            "Epoch_Loss - 1.3479992293975722 , accuracy : 9.889350638716033\n",
            "\n",
            "Epoch accuracy : 9.889350638716033\n",
            "\n",
            "Epoch - 40 / 100\n",
            "Epoch_Loss - 1.337992034327816 , accuracy : 9.934004462823466\n",
            "\n",
            "Epoch accuracy : 9.934004462823466\n",
            "\n",
            "Epoch - 41 / 100\n",
            "Epoch_Loss - 1.3202407863778127 , accuracy : 10.045575049132013\n",
            "\n",
            "Epoch accuracy : 10.045575049132013\n",
            "\n",
            "Epoch - 42 / 100\n",
            "Epoch_Loss - 1.3066601383853966 , accuracy : 10.13680191614806\n",
            "\n",
            "Epoch accuracy : 10.13680191614806\n",
            "\n",
            "Epoch - 43 / 100\n",
            "Epoch_Loss - 1.2891529336781569 , accuracy : 10.222399074680656\n",
            "\n",
            "Epoch accuracy : 10.222399074680656\n",
            "\n",
            "Epoch - 44 / 100\n",
            "Epoch_Loss - 1.2772664343807059 , accuracy : 10.301598837209317\n",
            "\n",
            "Epoch accuracy : 10.301598837209317\n",
            "\n",
            "Epoch - 45 / 100\n",
            "Epoch_Loss - 1.2694128567064311 , accuracy : 10.335632983950227\n",
            "\n",
            "Epoch accuracy : 10.335632983950227\n",
            "\n",
            "Epoch - 46 / 100\n",
            "Epoch_Loss - 1.2552234278598302 , accuracy : 10.409842777595824\n",
            "\n",
            "Epoch accuracy : 10.409842777595824\n",
            "\n",
            "Epoch - 47 / 100\n",
            "Epoch_Loss - 1.2377265389536467 , accuracy : 10.516807238781535\n",
            "\n",
            "Epoch accuracy : 10.516807238781535\n",
            "\n",
            "Epoch - 48 / 100\n",
            "Epoch_Loss - 1.2426058490511398 , accuracy : 10.470234195872925\n",
            "\n",
            "Epoch accuracy : 10.470234195872925\n",
            "\n",
            "Epoch - 49 / 100\n",
            "Epoch_Loss - 1.2194770616544803 , accuracy : 10.629529356370794\n",
            "\n",
            "Epoch accuracy : 10.629529356370794\n",
            "\n",
            "Epoch - 50 / 100\n",
            "Epoch_Loss - 1.2166665943575576 , accuracy : 10.629529356370794\n",
            "\n",
            "Epoch accuracy : 10.629529356370794\n",
            "\n",
            "Epoch - 51 / 100\n",
            "Epoch_Loss - 1.2037660286460123 , accuracy : 10.700924295774655\n",
            "\n",
            "Epoch accuracy : 10.700924295774655\n",
            "\n",
            "Epoch - 52 / 100\n",
            "Epoch_Loss - 1.2011845204192149 , accuracy : 10.691839993449083\n",
            "\n",
            "Epoch accuracy : 10.691839993449083\n",
            "\n",
            "Epoch - 53 / 100\n",
            "Epoch_Loss - 1.1900759641553316 , accuracy : 10.7706559122175\n",
            "\n",
            "Epoch accuracy : 10.7706559122175\n",
            "\n",
            "Epoch - 54 / 100\n",
            "Epoch_Loss - 1.1745711027736394 , accuracy : 10.867896331477251\n",
            "\n",
            "Epoch accuracy : 10.867896331477251\n",
            "\n",
            "Epoch - 55 / 100\n",
            "Epoch_Loss - 1.1708953791940715 , accuracy : 10.867384539796936\n",
            "\n",
            "Epoch accuracy : 10.867384539796936\n",
            "\n",
            "Epoch - 56 / 100\n",
            "Epoch_Loss - 1.1544485872899983 , accuracy : 10.962705740255505\n",
            "\n",
            "Epoch accuracy : 10.962705740255505\n",
            "\n",
            "Epoch - 57 / 100\n",
            "Epoch_Loss - 1.157334245426554 , accuracy : 10.960018833933857\n",
            "\n",
            "Epoch accuracy : 10.960018833933857\n",
            "\n",
            "Epoch - 58 / 100\n",
            "Epoch_Loss - 1.1383020281791687 , accuracy : 11.059178471994773\n",
            "\n",
            "Epoch accuracy : 11.059178471994773\n",
            "\n",
            "Epoch - 59 / 100\n",
            "Epoch_Loss - 1.1303051340747887 , accuracy : 11.117522723550618\n",
            "\n",
            "Epoch accuracy : 11.117522723550618\n",
            "\n",
            "Epoch - 60 / 100\n",
            "Epoch_Loss - 1.1255475223903926 , accuracy : 11.13965771372422\n",
            "\n",
            "Epoch accuracy : 11.13965771372422\n",
            "\n",
            "Epoch - 61 / 100\n",
            "Epoch_Loss - 1.1172282972805936 , accuracy : 11.171772641663951\n",
            "\n",
            "Epoch accuracy : 11.171772641663951\n",
            "\n",
            "Epoch - 62 / 100\n",
            "Epoch_Loss - 1.1153709586237517 , accuracy : 11.181240787749774\n",
            "\n",
            "Epoch accuracy : 11.181240787749774\n",
            "\n",
            "Epoch - 63 / 100\n",
            "Epoch_Loss - 1.109946891035832 , accuracy : 11.226278455617438\n",
            "\n",
            "Epoch accuracy : 11.226278455617438\n",
            "\n",
            "Epoch - 64 / 100\n",
            "Epoch_Loss - 1.099499395615618 , accuracy : 11.261208237798899\n",
            "\n",
            "Epoch accuracy : 11.261208237798899\n",
            "\n",
            "Epoch - 65 / 100\n",
            "Epoch_Loss - 1.0881076543263986 , accuracy : 11.35729712577793\n",
            "\n",
            "Epoch accuracy : 11.35729712577793\n",
            "\n",
            "Epoch - 66 / 100\n",
            "Epoch_Loss - 1.0795971843558299 , accuracy : 11.411802939731425\n",
            "\n",
            "Epoch accuracy : 11.411802939731425\n",
            "\n",
            "Epoch - 67 / 100\n",
            "Epoch_Loss - 1.0814589522254299 , accuracy : 11.372011136586973\n",
            "\n",
            "Epoch accuracy : 11.372011136586973\n",
            "\n",
            "Epoch - 68 / 100\n",
            "Epoch_Loss - 1.080436733826785 , accuracy : 11.38045569931217\n",
            "\n",
            "Epoch accuracy : 11.38045569931217\n",
            "\n",
            "Epoch - 69 / 100\n",
            "Epoch_Loss - 1.0645805584712766 , accuracy : 11.46387774320342\n",
            "\n",
            "Epoch accuracy : 11.46387774320342\n",
            "\n",
            "Epoch - 70 / 100\n",
            "Epoch_Loss - 1.0585423863269914 , accuracy : 11.504309285948267\n",
            "\n",
            "Epoch accuracy : 11.504309285948267\n",
            "\n",
            "Epoch - 71 / 100\n",
            "Epoch_Loss - 1.05078894067818 , accuracy : 11.574040902391104\n",
            "\n",
            "Epoch accuracy : 11.574040902391104\n",
            "\n",
            "Epoch - 72 / 100\n",
            "Epoch_Loss - 1.044195553366567 , accuracy : 11.591953611202111\n",
            "\n",
            "Epoch accuracy : 11.591953611202111\n",
            "\n",
            "Epoch - 73 / 100\n",
            "Epoch_Loss - 1.043662558558961 , accuracy : 11.604748403209971\n",
            "\n",
            "Epoch accuracy : 11.604748403209971\n",
            "\n",
            "Epoch - 74 / 100\n",
            "Epoch_Loss - 1.0276470868520333 , accuracy : 11.701477030789398\n",
            "\n",
            "Epoch accuracy : 11.701477030789398\n",
            "\n",
            "Epoch - 75 / 100\n",
            "Epoch_Loss - 1.0330924400141541 , accuracy : 11.652984769079612\n",
            "\n",
            "Epoch accuracy : 11.652984769079612\n",
            "\n",
            "Epoch - 76 / 100\n",
            "Epoch_Loss - 1.0266558830167207 , accuracy : 11.707490583033096\n",
            "\n",
            "Epoch accuracy : 11.707490583033096\n",
            "\n",
            "Epoch - 77 / 100\n",
            "Epoch_Loss - 1.0242108920930137 , accuracy : 11.698662176547677\n",
            "\n",
            "Epoch accuracy : 11.698662176547677\n",
            "\n",
            "Epoch - 78 / 100\n",
            "Epoch_Loss - 1.0085612103133135 , accuracy : 11.810744554536535\n",
            "\n",
            "Epoch accuracy : 11.810744554536535\n",
            "\n",
            "Epoch - 79 / 100\n",
            "Epoch_Loss - 1.014013686230485 , accuracy : 11.78579471012121\n",
            "\n",
            "Epoch accuracy : 11.78579471012121\n",
            "\n",
            "Epoch - 80 / 100\n",
            "Epoch_Loss - 1.00899877640563 , accuracy : 11.793215689485766\n",
            "\n",
            "Epoch accuracy : 11.793215689485766\n",
            "\n",
            "Epoch - 81 / 100\n",
            "Epoch_Loss - 1.0076206465002517 , accuracy : 11.808825335735358\n",
            "\n",
            "Epoch accuracy : 11.808825335735358\n",
            "\n",
            "Epoch - 82 / 100\n",
            "Epoch_Loss - 0.9920083347340705 , accuracy : 11.907345234195882\n",
            "\n",
            "Epoch accuracy : 11.907345234195882\n",
            "\n",
            "Epoch - 83 / 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NseLh6OTuU_s"
      },
      "source": [
        "  with torch.no_grad():\n",
        "\n",
        "    input = torch.tensor(prepared_questions_train[0 : 20]).to(device)\n",
        "    target = torch.tensor(prefix_equations_list_train[0 : 20]).to(device)\n",
        "\n",
        "    # Pass the input and target for model's forward method\n",
        "    output = model(input.transpose(0,1), target.transpose(0,1))\n",
        "\n",
        "    output = output.permute(1,2,0)\n",
        "\n",
        "    y_pred = output.permute(0,2,1)\n",
        "    _, y_pred = torch.max(y_pred, dim = 2)\n",
        "    total_acc =0\n",
        "    for true,pred in zip(target,y_pred):\n",
        "      tp=0\n",
        "      total=0\n",
        "      acc =0\n",
        "      for t,t_h in zip(true,pred):\n",
        "        if(t!=0):\n",
        "          if(t==t_h):\n",
        "            tp+=1\n",
        "          total+=1\n",
        "      acc = tp/total\n",
        "      total_acc += acc\n",
        "\n",
        "        \n",
        "    acc = total_acc / target.shape[0]\n",
        "    acc = acc * 100\n",
        "    acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sn_5EIRQKDT2",
        "outputId": "6362b9e6-f1d8-4b8c-ef7b-463684dcc157"
      },
      "source": [
        "acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30.37162837162837"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVHGkLWaKER9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}