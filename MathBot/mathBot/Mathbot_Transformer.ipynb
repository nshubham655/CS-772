{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mathbot_Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "i0ARP8oYeGpb",
        "fVbSOYuyeaPm",
        "gq-Kw2rLgpme",
        "EgfEMiove1Zn",
        "eqLdtAAPorvt",
        "R6bSvwJ1e_g8",
        "lxvJ4M-pouYH",
        "_wlWv0HSptaN",
        "QLT6USM-htw3",
        "fpi8JaiblDOh",
        "spiU0QDI2egM",
        "0SFJifWj7AtQ",
        "f6ERVfc2FKJ8"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzFGQDq_eQhq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a30d8021-4241-47ba-b73f-4721d6b3d771"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYCsVSqCmxrG"
      },
      "source": [
        "<h1> Import Libraries Here </h1>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxTFbysWm-t1"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from nltk.corpus import stopwords  \n",
        "from nltk.tokenize import word_tokenize  \n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing import sequence\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMLSLbdIorIy"
      },
      "source": [
        "<h1> Read Training Data Here </h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbkJoeVzou7V"
      },
      "source": [
        "prepared_dataset=pd.read_csv('/content/drive/MyDrive/Math23K_English_with_data_prep.csv')\n",
        "#prepared_dataset.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KWR8UdVq78w"
      },
      "source": [
        "with open('/content/drive/MyDrive/equations_data.json') as f:\n",
        "  prefix_equations_list = json.load(f)\n",
        "#print(len(prefix_equations_list))\n",
        "#print(prefix_equations_list[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Cz0d6iqpvbp"
      },
      "source": [
        "<h1> Extract Parts Of Prepared Dataset Here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXllcE3Ppd2N"
      },
      "source": [
        "prepared_questions=prepared_dataset['prepared_question'].values.tolist()\n",
        "#print(len(prepared_questions))\n",
        "#print(prepared_questions[0])   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qW0aiWjp_A5"
      },
      "source": [
        "normal_questions=prepared_dataset['segmented_question'].values.tolist()\n",
        "#print(len(normal_questions))\n",
        "#print(normal_questions[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geyzCUzJqb8Z"
      },
      "source": [
        "infix_equations=prepared_dataset['equation'].values.tolist()\n",
        "#print(len(infix_equations))\n",
        "#print(infix_equations[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvp2L1s9qm7N"
      },
      "source": [
        "answers=prepared_dataset['ans'].values.tolist()\n",
        "#print(len(answers))\n",
        "#print(answers[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81DDoSR4dwgO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_m3DTVtrnk-"
      },
      "source": [
        "<h1> Preprocess The Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkW6lrnxMiFH"
      },
      "source": [
        "<h2> Remove the unnecessary Data (No Prefix) </h2> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7IHnImgS4UC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7f7807a-6567-4e73-ad92-af75a192ea9b"
      },
      "source": [
        "idx_to_remove=[i for i in range(len(prefix_equations_list)) if prefix_equations_list[i]==\"no_prefix\"]\n",
        "prepared_questions=[prepared_questions[i] for i in range(len(prefix_equations_list)) if prefix_equations_list[i] != \"no_prefix\"]\n",
        "normal_questions=[normal_questions[i] for i in range(len(prefix_equations_list)) if prefix_equations_list[i] != \"no_prefix\"]\n",
        "infix_equations=[infix_equations[i] for i in range(len(prefix_equations_list)) if prefix_equations_list[i] != \"no_prefix\"]\n",
        "answers=[answers[i] for i in range(len(prefix_equations_list)) if prefix_equations_list[i] != \"no_prefix\"]\n",
        "prefix_equations_list=[equation for equation in prefix_equations_list if equation != \"no_prefix\"]\n",
        "\n",
        "\n",
        "idx_to_remove_chinnese=[i for i in range(len(infix_equations)) if infix_equations[i]==\"x=80千米/小时\"]\n",
        "print(idx_to_remove_chinnese)\n",
        "if len(idx_to_remove_chinnese) >=1:\n",
        "  prepared_questions.pop(idx_to_remove_chinnese[0])\n",
        "  normal_questions.pop(idx_to_remove_chinnese[0])\n",
        "  infix_equations.pop(idx_to_remove_chinnese[0])\n",
        "  answers.pop(idx_to_remove_chinnese[0])\n",
        "  prefix_equations_list.pop(idx_to_remove_chinnese[0])\n",
        "\n",
        "# print(len(idx_to_remove))\n",
        "# print(idx_to_remove)\n",
        "# print(len(prefix_equations_list))\n",
        "# print(len(prepared_questions))\n",
        "# print(len(normal_questions)) \n",
        "# print(len(infix_equations))\n",
        "# print(len(answers))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[10149]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3N3-65lT425"
      },
      "source": [
        "# print(prefix_equations_list[2578])\n",
        "# print(prepared_questions[2578])\n",
        "# print(normal_questions[2578])\n",
        "# print(infix_equations[2578])\n",
        "# print(answers[2578])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ccJ9MeXr93B"
      },
      "source": [
        "<h2> Tokenize  </h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESIpJmsoqt15",
        "outputId": "57810843-8294-4e49-fa6e-e4b142dff9c6"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMbR11uLsA94"
      },
      "source": [
        "temp_questions=list()\n",
        "for elem in prepared_questions:\n",
        "  temp_questions.append(word_tokenize(elem))\n",
        "prepared_questions=temp_questions\n",
        "#print(len(prepared_questions))\n",
        "#print(prepared_questions[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75ifyQW6tUIj"
      },
      "source": [
        "<h1> Create Vocab Input and Output Both</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tocVR88B0a8X",
        "outputId": "6ca01725-69e0-4fe2-f3ee-87470761ddcd"
      },
      "source": [
        "index_to_word_input=['<pad>']\n",
        "for question in prepared_questions:\n",
        "  for word in question:\n",
        "    if(word not in index_to_word_input):\n",
        "      index_to_word_input.append(word)\n",
        "#print(len(index_to_word_input))\n",
        "#print(index_to_word_input[0])\n",
        "input_vocab_size=len(index_to_word_input)\n",
        "input_vocab_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7805"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laUcYR89d2i2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "425cc146-e3b8-4484-bcaf-52ae722689a9"
      },
      "source": [
        "output_vocab_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTF1uNI00CN0"
      },
      "source": [
        "word_to_index_input={'<pad>':0}\n",
        "for question in prepared_questions:\n",
        "  for word in question:\n",
        "    if(word not in word_to_index_input.keys()):\n",
        "      idx=index_to_word_input.index(word)\n",
        "      word_to_index_input[word]=idx\n",
        "#print(len(word_to_index_input))\n",
        "#print(word_to_index_input[\"n0\"])\n",
        "#print(word_to_index_input[\"n1\"])\n",
        "#print(word_to_index_input[\"children\"])\n",
        "#print(word_to_index_input['<pad>'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iakcke7Zs4Zh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2c6fafa-f1da-4cf7-d698-b322d033a731"
      },
      "source": [
        "index_to_word_output=['<pad>','<try>']\n",
        "for equation in prefix_equations_list:\n",
        "  for elem in equation:\n",
        "    if elem not in index_to_word_output:\n",
        "      index_to_word_output.append(elem)\n",
        "# print(len(index_to_word_output))\n",
        "# print(index_to_word_output[0])\n",
        "index_to_word_output.append('<start>')\n",
        "index_to_word_output.append('<end>')\n",
        "output_vocab_size=len(index_to_word_output)\n",
        "print(output_vocab_size)\n",
        "print(index_to_word_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33\n",
            "['<pad>', '<try>', '*', '-', 'n1', '1', 'n0', '+', 'n2', '/', 'n4', 'n3', 'n6', '7', 'n5', 'n7', '3', '6', '5', '0', '4', '2', '8', '^', '9', 'n8', 'n9', 'n10', 'n11', 'n13', 'n15', '<start>', '<end>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4Re5mAJtbGH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1140bca8-ee9d-4214-e540-2dd42a8a8994"
      },
      "source": [
        "word_to_index_output={'<pad>':0,'<try>':1}\n",
        "for word in index_to_word_output:\n",
        "  if word not in word_to_index_output.keys():\n",
        "    word_to_index_output[word]=index_to_word_output.index(word)\n",
        "print(len(word_to_index_output))\n",
        "print(word_to_index_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33\n",
            "{'<pad>': 0, '<try>': 1, '*': 2, '-': 3, 'n1': 4, '1': 5, 'n0': 6, '+': 7, 'n2': 8, '/': 9, 'n4': 10, 'n3': 11, 'n6': 12, '7': 13, 'n5': 14, 'n7': 15, '3': 16, '6': 17, '5': 18, '0': 19, '4': 20, '2': 21, '8': 22, '^': 23, '9': 24, 'n8': 25, 'n9': 26, 'n10': 27, 'n11': 28, 'n13': 29, 'n15': 30, '<start>': 31, '<end>': 32}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHPTTFziZ97D"
      },
      "source": [
        "<h1> Encode Data </h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AIg1FFQ3qsu"
      },
      "source": [
        "prepared_questions_temp=list()\n",
        "for question in prepared_questions:\n",
        "  question_temp=list()\n",
        "  for word in question:\n",
        "    question_temp.append(word_to_index_input[word])\n",
        "  prepared_questions_temp.append(question_temp)\n",
        "# print(prepared_questions[11235])\n",
        "prepared_questions=prepared_questions_temp\n",
        "# print(prepared_questions[11235])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OT-oHTKKcD6D"
      },
      "source": [
        "<h1> Padding </h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhbPfmofa1mC"
      },
      "source": [
        "max_len=max(len(question) for question in prepared_questions)\n",
        "#print(max_len)\n",
        "prepared_questions= sequence.pad_sequences(prepared_questions, maxlen=max_len,padding=\"post\")\n",
        "# print(prepared_questions[2])\n",
        "# print(len(prepared_questions))\n",
        "#reviews.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9mu80MBon0q"
      },
      "source": [
        "<h1> Encode Equations </h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yflmi6kwormQ"
      },
      "source": [
        "prefix_equations_list_temp=list()\n",
        "for equation in prefix_equations_list:\n",
        "  equation_temp=[word_to_index_output['<start>']]\n",
        "  for elem in equation:\n",
        "    equation_temp.append(word_to_index_output[elem])\n",
        "  equation_temp.append(word_to_index_output['<end>'])\n",
        "  prefix_equations_list_temp.append(equation_temp)\n",
        "prefix_equations_list=prefix_equations_list_temp\n",
        "#print(prefix_equations_list[0])\n",
        "#print(prefix_equations_list[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qELG9F2peej"
      },
      "source": [
        "<h1> Padding Equations</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNXZeA2gphuQ"
      },
      "source": [
        "max_len=max(len(equation) for equation in prefix_equations_list)\n",
        "#print(max_len)\n",
        "prefix_equations_list= sequence.pad_sequences(prefix_equations_list, maxlen=max_len,padding=\"post\")\n",
        "#print(prefix_equations_list[0])\n",
        "#print(prefix_equations_list[2])\n",
        "#print(len(prefix_equations_list))\n",
        "#reviews.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4TGAcLmf1Fx"
      },
      "source": [
        "<h1> Import Pytorch/Tensorflow Dependencies Here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKO8f7KNf4T3"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset,DataLoader \n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.sampler import WeightedRandomSampler\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQLZDsw3tFPW"
      },
      "source": [
        "import collections\n",
        "import logging\n",
        "import os\n",
        "import pathlib\n",
        "import re\n",
        "import string\n",
        "import sys\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "#import tensorflow_text as text\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjlWdr1Zf90n"
      },
      "source": [
        "<h1> Split Data into Train and Validation and Test</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfQHQqqUsVSu"
      },
      "source": [
        "prepared_questions_train, prepared_questions_test, prefix_equations_list_train, prefix_equations_list_test = train_test_split(prepared_questions,prefix_equations_list, train_size=0.8)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvpzBzPUgA6l"
      },
      "source": [
        "#prepared_questions_train, prepared_questions_test, prefix_equations_list_train, prefix_equations_list_test = train_test_split(prepared_questions,prefix_equations_list, train_size=0.9)\n",
        "## print(len(prepared_questions_train))\n",
        "## print(len(prefix_equations_list_train))\n",
        "## print(len(prepared_questions_test))\n",
        "## print(len(prefix_equations_list_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz9HFaIVgelm"
      },
      "source": [
        "#prepared_questions_train, prepared_questions_val, prefix_equations_list_train, prefix_equations_list_val = train_test_split(prepared_questions_train,prefix_equations_list_train, train_size=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYUhIgWnhG4_"
      },
      "source": [
        "BUFFER_SIZE = len(prepared_questions_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(prepared_questions_train)//BATCH_SIZE\n",
        "dataset = tf.data.Dataset.from_tensor_slices((prepared_questions_train, prefix_equations_list_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "input_vocab_size = input_vocab_size\n",
        "target_vocab_size = 42\n",
        "dropout_rate = 0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RO8kRw2humLN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqjLcutlcubG"
      },
      "source": [
        "# We provide positional information about the data to the model,\n",
        "# otherwise each sentence will be treated as Bag of Words\n",
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "  return pos * angle_rates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4LBjCfbd36x"
      },
      "source": [
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "  \n",
        "  # apply sin to even indices in the array; 2i\n",
        "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "  \n",
        "  # apply cos to odd indices in the array; 2i+1\n",
        "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "    \n",
        "  pos_encoding = angle_rads[np.newaxis, ...]\n",
        "    \n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0ARP8oYeGpb"
      },
      "source": [
        "#### Masking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPU51VjMeIOp"
      },
      "source": [
        "# mask all elements are that not words (padding) so that it is not treated as input\n",
        "def create_padding_mask(seq):\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "  \n",
        "  # add extra dimensions to add the padding\n",
        "  # to the attention logits.\n",
        "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLLyLy3_eS69"
      },
      "source": [
        "def create_look_ahead_mask(size):\n",
        "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "  return mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsFCUWbNz-jo"
      },
      "source": [
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVbSOYuyeaPm"
      },
      "source": [
        "\n",
        "#### Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW-49jyBeZy0"
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "  \n",
        "  # scale matmul_qk\n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "  # add the mask to the scaled tensor.\n",
        "  if mask is not None:\n",
        "    scaled_attention_logits += (mask * -1e9)  \n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "  # add up to 1.\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "  return output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhCANAddefdq"
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "    \n",
        "    assert d_model % self.num_heads == 0\n",
        "    \n",
        "    self.depth = d_model // self.num_heads\n",
        "    \n",
        "    self.wq = tf.keras.layers.Dense(d_model)\n",
        "    self.wk = tf.keras.layers.Dense(d_model)\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "    \n",
        "    self.dense = tf.keras.layers.Dense(d_model)\n",
        "        \n",
        "  def split_heads(self, x, batch_size):\n",
        "    \"\"\"Split the last dimension into (num_heads, depth).\n",
        "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "    \"\"\"\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "    \n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "    \n",
        "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "    \n",
        "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "    \n",
        "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "        q, k, v, mask)\n",
        "    \n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "    concat_attention = tf.reshape(scaled_attention, \n",
        "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "        \n",
        "    return output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gq-Kw2rLgpme"
      },
      "source": [
        "#### Pointwise Feed forward network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mNE0fJvefaO"
      },
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgfEMiove1Zn"
      },
      "source": [
        "#### Encoder Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qQc6o64eySC"
      },
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    # normalize data per feature instead of batch\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    \n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "  def call(self, x, training, mask):\n",
        "    # Multi-head attention layer\n",
        "    attn_output, _ = self.mha(x, x, x, mask) \n",
        "    attn_output = self.dropout1(attn_output, training=training)\n",
        "    # add residual connection to avoid vanishing gradient problem\n",
        "    out1 = self.layernorm1(x + attn_output)\n",
        "    \n",
        "    # Feedforward layer\n",
        "    ffn_output = self.ffn(out1)\n",
        "    ffn_output = self.dropout2(ffn_output, training=training)\n",
        "    # add residual connection to avoid vanishing gradient problem\n",
        "    out2 = self.layernorm2(out1 + ffn_output)\n",
        "    return out2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqLdtAAPorvt"
      },
      "source": [
        "#### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WsCLoYEfC1L"
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
        "                                            self.d_model)\n",
        "    \n",
        "    # Create encoder layers (count: num_layers)\n",
        "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
        "                       for _ in range(num_layers)]\n",
        "  \n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "        \n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "\n",
        "    # adding embedding and position encoding.\n",
        "    x = self.embedding(x)  \n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "    \n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x, training, mask)\n",
        "    \n",
        "    return x "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6bSvwJ1e_g8"
      },
      "source": [
        "#### Decoder Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQgt7OcdeyKr"
      },
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        " \n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    \n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    \n",
        "  def call(self, x, enc_output, training, \n",
        "           look_ahead_mask, padding_mask):\n",
        "\n",
        "    # Masked multihead attention layer (padding + look-ahead)\n",
        "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n",
        "    attn1 = self.dropout1(attn1, training=training)\n",
        "    # again add residual connection\n",
        "    out1 = self.layernorm1(attn1 + x)\n",
        "    \n",
        "    # Masked multihead attention layer (only padding)\n",
        "    # with input from encoder as Key and Value, and input from previous layer as Query\n",
        "    attn2, attn_weights_block2 = self.mha2(\n",
        "        enc_output, enc_output, out1, padding_mask)\n",
        "    attn2 = self.dropout2(attn2, training=training)\n",
        "    # again add residual connection\n",
        "    out2 = self.layernorm2(attn2 + out1)\n",
        "    \n",
        "    # Feedforward layer\n",
        "    ffn_output = self.ffn(out2)\n",
        "    ffn_output = self.dropout3(ffn_output, training=training)\n",
        "    # again add residual connection\n",
        "    out3 = self.layernorm3(ffn_output + out2)\n",
        "    return out3, attn_weights_block1, attn_weights_block2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxvJ4M-pouYH"
      },
      "source": [
        "#### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8M_UsFHfCtH"
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "     \n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "    \n",
        "    # Create decoder layers (count: num_layers)\n",
        "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
        "                       for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "  def call(self, x, enc_output, training, \n",
        "           look_ahead_mask, padding_mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    attention_weights = {}\n",
        "    \n",
        "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "    \n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    \n",
        "    x += self.pos_encoding[:,:seq_len,:]\n",
        "    \n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
        "                                             look_ahead_mask, padding_mask)\n",
        "      \n",
        "      # store attenion weights, they can be used to visualize while translating\n",
        "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "    \n",
        "    return x, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wlWv0HSptaN"
      },
      "source": [
        "#### Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3ldNVklfaMY"
      },
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
        "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "    super(Transformer, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
        "                           input_vocab_size, pe_input, rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
        "                           target_vocab_size, pe_target, rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "    \n",
        "  def call(self, inp, tar, training, enc_padding_mask, \n",
        "           look_ahead_mask, dec_padding_mask):\n",
        "\n",
        "    # Pass the input to the encoder\n",
        "    enc_output = self.encoder(inp, training, enc_padding_mask)\n",
        "    \n",
        "    # Pass the encoder output to the decoder\n",
        "    dec_output, attention_weights = self.decoder(\n",
        "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "    \n",
        "    # Pass the decoder output to the last linear layer\n",
        "    final_output = self.final_layer(dec_output)\n",
        "    \n",
        "    return final_output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLT6USM-htw3"
      },
      "source": [
        "#### Optimizer and Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "588zG6wOfaGd"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "    \n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "    \n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "    \n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfEAPe3FfZ-8"
      },
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "# Adam optimizer with a custom learning rate\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
        "                                     epsilon=1e-9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ree_sJLFfZfm"
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "il10DQXPefP-"
      },
      "source": [
        "def loss_function(real, pred):\n",
        "  # Apply a mask to paddings (0)\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "  \n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzVTb8RmefDd"
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "    name='train_accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6QXJV9rh8nc"
      },
      "source": [
        "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
        "                          input_vocab_size, target_vocab_size, \n",
        "                          pe_input=input_vocab_size, \n",
        "                          pe_target=target_vocab_size,\n",
        "                          rate=dropout_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnNv_E9Wh8jl"
      },
      "source": [
        "def create_masks(inp, tar):\n",
        "  # Encoder padding mask\n",
        "  enc_padding_mask = create_padding_mask(inp)\n",
        "  \n",
        "  # Decoder padding mask\n",
        "  dec_padding_mask = create_padding_mask(inp)\n",
        "  \n",
        "  # Look ahead mask (for hiding the rest of the sequence in the 1st decoder attention layer)\n",
        "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "  dec_target_padding_mask = create_padding_mask(tar)\n",
        "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "  \n",
        "  return enc_padding_mask, combined_mask, dec_padding_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7etu6ariHqK"
      },
      "source": [
        "### Checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkZOgiXPiHqM"
      },
      "source": [
        "# !rm -r /gdrive/My\\ Drive/ADL\\ Project/checkpoints/training_checkpoints/akshata_transfomer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72OsBxu6iHqO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cb7ad77-f120-4ce7-ea9c-3a4e416cddc7"
      },
      "source": [
        "checkpoint_dir = os.path.join(\"/content/drive/MyDrive/checkpoints\")\n",
        "checkpoint_dir = os.path.join(\"/content/drive/MyDrive/checkpoints/math_bot\")\n",
        "\n",
        "print(\"Checkpoints directory is\", checkpoint_dir)\n",
        "if os.path.exists(checkpoint_dir):\n",
        "  print(\"Checkpoints folder already exists\")\n",
        "else:\n",
        "  print(\"Creating a checkpoints directory\")\n",
        "  os.makedirs(checkpoint_dir)\n",
        "\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(transformer=transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_to_keep=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checkpoints directory is /content/drive/MyDrive/checkpoints/math_bot\n",
            "Checkpoints folder already exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbxp9qB_iHqS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "109a44ab-2e80-4c53-cd0f-14c54f3cd6ab"
      },
      "source": [
        "latest = ckpt_manager.latest_checkpoint\n",
        "latest"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/checkpoints/math_bot/ckpt-5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekNEXzDJiHqW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79bd8b8a-a9d4-4c1a-87f6-dd8c7e071aed"
      },
      "source": [
        "if latest:\n",
        "  epoch_num = int(latest.split('/')[-1].split('-')[-1])\n",
        "  checkpoint.restore(latest)\n",
        "  print ('Latest checkpoint restored!!')\n",
        "else:\n",
        "  epoch_num = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Latest checkpoint restored!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leaHQMBaiHqX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4910c437-42cb-43c6-a6a8-4f8d00326d4b"
      },
      "source": [
        "epoch_num"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jj0D4HuIatpn"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOcltIu0h8cr"
      },
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "def train_step(inp, tar):\n",
        "  tar_inp = tar[:, :-1]\n",
        "  tar_real = tar[:, 1:]\n",
        "  \n",
        "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "  \n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions, _ = transformer(inp, tar_inp,  True, enc_padding_mask, combined_mask, dec_padding_mask)\n",
        "    loss = loss_function(tar_real, predictions)\n",
        "\n",
        "  gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
        "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "  \n",
        "  train_loss(loss)\n",
        "  #print(tar_real)\n",
        "  #print(\"----------------------\")\n",
        "  #print(predictions)\n",
        "  train_accuracy(tar_real, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEqQmYLZh8R3"
      },
      "source": [
        "for epoch in range(epoch_num, EPOCHS):\n",
        "  start = time.time()\n",
        "  \n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  \n",
        "  # inp -> question, tar -> equation\n",
        "  for (batch, (inp, tar)) in enumerate(dataset):\n",
        "    #print(inp.shape)\n",
        "    #print(tar.shape)\n",
        "    train_step(inp, tar)\n",
        "    \n",
        "    if batch % 50 == 0:\n",
        "      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
        "          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
        "      \n",
        "  ckpt_save_path = ckpt_manager.save()\n",
        "  print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
        "                                                         ckpt_save_path))\n",
        "    \n",
        "  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
        "                                                train_loss.result(), \n",
        "                                                train_accuracy.result()))\n",
        "\n",
        "  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDJe10Di0dIY",
        "outputId": "5ce42b75-94b3-4997-c919-fa30bcd205ca"
      },
      "source": [
        "#jiang \n",
        "inp_sentence_words=\"troy   had  n0  apple . he gave n1 apple to prot . how many does he have left\"\n",
        "inp_sentence=list()\n",
        "inp_sentence_words_token=word_tokenize(inp_sentence_words)\n",
        "for elem in inp_sentence_words_token:\n",
        "  try:\n",
        "    inp_sentence.append(word_to_index_input[elem])\n",
        "  except:\n",
        "    inp_sentence.append(0)\n",
        "to_append_length=135-len(inp_sentence)\n",
        "for i in range(0,to_append_length):\n",
        "  inp_sentence.append(0)\n",
        "print(len(inp_sentence))\n",
        "print(inp_sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "135\n",
            "[0, 114, 20, 746, 16, 64, 428, 33, 746, 9, 0, 16, 34, 35, 80, 64, 81, 148, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JU2AuTt20e9n",
        "outputId": "942cf4fb-5023-4ac6-b024-c0279e225b82"
      },
      "source": [
        "MAX_LENGTH=42\n",
        "# inp_sentence=[11, 1770,  643, 1771, 1052,  751, 1575,   28,   51,  567,   20,71,  141,   23,   33, 1575,  148,   16,   34,   35, 1575,   80,   37,\n",
        "#         1770,  643, 1771,   81,   39,    0,    0,    0,    0,    0,    0,\n",
        "#            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
        "#            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
        "#            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
        "#            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
        "#            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
        "#            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
        "#            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
        "#            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
        "#            0,    0,    0,    0,    0]\n",
        "print(len(inp_sentence))\n",
        "encoder_input = tf.expand_dims(inp_sentence, 0)\n",
        "decoder_input = [word_to_index_output['<start>']]\n",
        "output = tf.expand_dims(decoder_input, 0)\n",
        "for i in range(MAX_LENGTH):\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "        encoder_input, output)\n",
        "    predictions, attention_weights = transformer(encoder_input, \n",
        "                                                    output,\n",
        "                                                    False,\n",
        "                                                    enc_padding_mask,\n",
        "                                                    combined_mask,\n",
        "                                                    dec_padding_mask)\n",
        "    predictions = predictions[: ,-1:, :] \n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "    \n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if predicted_id == 32:\n",
        "      #print(tf.squeeze(output, axis=0), attention_weights)\n",
        "      break\n",
        "    \n",
        "    # concatentate the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "print(tf.squeeze(output, axis=0))\n",
        "        \n",
        "    #print(predictions)\n",
        "    # select the last word from the seq_len dimension\n",
        "#predictions = predictions[: ,-1:, :] \n",
        "#predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "135\n",
            "tf.Tensor([31  3  6  4], shape=(4,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n33GH32C0hDm",
        "outputId": "153a5022-863a-4886-e079-b020f469b370"
      },
      "source": [
        "output=tf.squeeze(output, axis=0)\n",
        "for elem in output:\n",
        "  if(elem!=31):\n",
        "    print(index_to_word_output[elem])\n",
        "  elif elem ==32:\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "n0\n",
            "n1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rob3sgc_0jJc",
        "outputId": "33c65fd2-44aa-458c-c428-dd3fc4f0de7b"
      },
      "source": [
        "for elem in inp_sentence:\n",
        "  print(index_to_word_input[elem],end=' ')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<pad> had n0 apple . he gave n1 apple to <pad> . how many does he have left <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OR-u_Lo45iHv"
      },
      "source": [
        "def predicted_eqn(inp_sentence_words):  \n",
        "  MAX_LENGTH=42\n",
        "  input_sentence_token=word_tokenize(inp_sentence_words)\n",
        "  input_sentence=[]\n",
        "  for word in input_sentence_token:\n",
        "    try:\n",
        "      input_sentence.append(word_to_index_input[word])\n",
        "    except:\n",
        "      input_sentence.append(0)\n",
        "  to_pad=42-len(input_sentence_token)\n",
        "  for _ in range(0,to_pad):\n",
        "    input_sentence.append(0)\n",
        "  #print(input_sentence)\n",
        "  encoder_input = tf.expand_dims(input_sentence, 0)\n",
        "  decoder_input = [word_to_index_output['<start>']]\n",
        "  output = tf.expand_dims(decoder_input, 0)\n",
        "  for i in range(MAX_LENGTH):\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)\n",
        "    predictions, attention_weights = transformer(encoder_input, \n",
        "                                                  output,\n",
        "                                                  False,\n",
        "                                                  enc_padding_mask,\n",
        "                                                  combined_mask,\n",
        "                                                  dec_padding_mask)\n",
        "    predictions = predictions[: ,-1:, :] \n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "    \n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if predicted_id == word_to_index_output['<end>']:\n",
        "      #print(tf.squeeze(output, axis=0), attention_weights)\n",
        "      break\n",
        "    \n",
        "    # concatentate the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "  output=tf.squeeze(output, axis=0)\n",
        "  output_ret=list()\n",
        "  for elem in output:\n",
        "    output_ret.append(index_to_word_output[elem])\n",
        "  return output_ret[1:]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZagAB_1T0b4r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxzNhzkhvuVl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd92367f-2c23-4ee1-beda-4c987d12fdff"
      },
      "source": [
        "for elem in output:\n",
        "  print(index_to_word_output[elem])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start>\n",
            "-\n",
            "n0\n",
            "n1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJmI3wOf-Ygn"
      },
      "source": [
        "with open('/content/drive/MyDrive/equations_data.json') as f:\n",
        "  prefix_equations_list_eval = json.load(f)\n",
        "#print(len(prefix_equations_list))\n",
        "#print(prefix_equations_list[0])\n",
        "prepared_dataset_eval=pd.read_csv('/content/drive/MyDrive/Math23K_English_with_data_prep.csv')\n",
        "#prepared_dataset.head()\n",
        "prepared_questions_eval=prepared_dataset_eval['prepared_question'].values.tolist()\n",
        "#print(len(prepared_questions))\n",
        "#print(prepared_questions[0])   \n",
        "normal_questions_eval=prepared_dataset_eval['segmented_question'].values.tolist()\n",
        "#print(len(normal_questions))\n",
        "#print(normal_questions[0])\n",
        "infix_equations_eval=prepared_dataset_eval['equation'].values.tolist()\n",
        "#print(len(infix_equations))\n",
        "#print(infix_equations[0])\n",
        "answers_eval=prepared_dataset_eval['ans'].values.tolist()\n",
        "#print(len(answers))\n",
        "#print(answers[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvJ8meSG-yxq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c19ff580-9935-4ddd-e2bb-6c5f65392371"
      },
      "source": [
        "idx_to_remove=[i for i in range(len(prefix_equations_list_eval)) if prefix_equations_list_eval[i]==\"no_prefix\"]\n",
        "prepared_questions_eval=[prepared_questions_eval[i] for i in range(len(prefix_equations_list_eval)) if prefix_equations_list_eval[i] != \"no_prefix\"]\n",
        "normal_questions_eval=[normal_questions_eval[i] for i in range(len(prefix_equations_list_eval)) if prefix_equations_list_eval[i] != \"no_prefix\"]\n",
        "infix_equations_eval=[infix_equations_eval[i] for i in range(len(prefix_equations_list_eval)) if prefix_equations_list_eval[i] != \"no_prefix\"]\n",
        "answers=[answers_eval[i] for i in range(len(prefix_equations_list_eval)) if prefix_equations_list_eval[i] != \"no_prefix\"]\n",
        "prefix_equations_list_eval=[equation for equation in prefix_equations_list_eval if equation != \"no_prefix\"]\n",
        "\n",
        "\n",
        "idx_to_remove_chinnese=[i for i in range(len(infix_equations_eval)) if infix_equations_eval[i]==\"x=80千米/小时\"]\n",
        "print(idx_to_remove_chinnese)\n",
        "if len(idx_to_remove_chinnese) >=1:\n",
        "  prepared_questions_eval.pop(idx_to_remove_chinnese[0])\n",
        "  normal_questions_eval.pop(idx_to_remove_chinnese[0])\n",
        "  infix_equations_eval.pop(idx_to_remove_chinnese[0])\n",
        "  answers_eval.pop(idx_to_remove_chinnese[0])\n",
        "  prefix_equations_list_eval.pop(idx_to_remove_chinnese[0])\n",
        "\n",
        "# print(len(idx_to_remove))\n",
        "# print(idx_to_remove)\n",
        "# print(len(prefix_equations_list))\n",
        "# print(len(prepared_questions))\n",
        "# print(len(normal_questions)) \n",
        "# print(len(infix_equations))\n",
        "# print(len(answers))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[10149]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtmB6OBgB5UY"
      },
      "source": [
        "def is_operand(c):\n",
        "    \"\"\"\n",
        "    Return True if the given char c is an operand, e.g. it is a number\n",
        "    \"\"\"\n",
        "    reject_list=['*','+','-','/','^']\n",
        "    if c in reject_list:\n",
        "      return False\n",
        "    return True\n",
        " \n",
        "#print(is_operand('1/3'))\n",
        "def evaluate_prefix(expression):\n",
        "    \"\"\"\n",
        "    Evaluate a given expression in prefix notation.\n",
        "    Asserts that the given expression is valid.\n",
        "    \"\"\"\n",
        "    stack = []\n",
        "    #print(expression)\n",
        "    #print(expression[::-1])\n",
        "    # iterate over the string in reverse order\n",
        "    for c in expression[::-1]:\n",
        " \n",
        "        # push operand to stack\n",
        "        if is_operand(c):\n",
        "            try:\n",
        "              stack.append(float(c))\n",
        "            except:\n",
        "              stack.append(float(c[0])/float(c[2]))\n",
        " \n",
        "        else:\n",
        "            # pop values from stack can calculate the result\n",
        "            # push the result onto the stack again\n",
        "            o1 = stack.pop()\n",
        "            o2 = stack.pop()\n",
        " \n",
        "            if c == '+':\n",
        "                stack.append(o1 + o2)\n",
        " \n",
        "            elif c == '-':\n",
        "                stack.append(o1 - o2)\n",
        " \n",
        "            elif c == '*':\n",
        "                stack.append(o1 * o2)\n",
        " \n",
        "            elif c == '/':\n",
        "                stack.append(o1 / o2)\n",
        "            elif c == '^':\n",
        "                stack.append(o1 ** o2)\n",
        "\n",
        " \n",
        "    return stack.pop()\n",
        " \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g85jGDvrdAGQ",
        "outputId": "9fc0968f-f15b-49b2-ccc5-7c6a0c2c1e1d"
      },
      "source": [
        "print(input_vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7805\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O76_m9iA7qPW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        },
        "outputId": "5ceed0fd-79ae-4375-9f4d-4f3b8a82395a"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "def text2int(textnum, numwords={}):\n",
        "    flag=False\n",
        "    if not numwords:\n",
        "      units = [\n",
        "        \"zero\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\",\n",
        "        \"nine\", \"ten\", \"eleven\", \"twelve\", \"thirteen\", \"fourteen\", \"fifteen\",\n",
        "        \"sixteen\", \"seventeen\", \"eighteen\", \"nineteen\"\n",
        "      ]\n",
        "      \n",
        "\n",
        "      tens = [\"\", \"\", \"twenty\", \"thirty\", \"forty\", \"fifty\", \"sixty\", \"seventy\", \"eighty\", \"ninety\"]\n",
        "\n",
        "      scales = []\n",
        "\n",
        "      #numwords[\"and\"] = (1, 0)\n",
        "      for idx, word in enumerate(units):    numwords[word] = (1, idx)\n",
        "      #for idx, word in enumerate(units1):    numwords[word] = (1, idx)\n",
        "      for idx, word in enumerate(tens):     numwords[word] = (1, idx * 10)\n",
        "      for idx, word in enumerate(scales):   numwords[word] = (10 ** (idx * 3 or 2), 0)\n",
        "\n",
        "    current = result = 0\n",
        "    for word in textnum.split():\n",
        "        if word not in numwords:\n",
        "          flag=True\n",
        "          return word,flag\n",
        "        else:\n",
        "            scale, increment = numwords[word]\n",
        "            current = current * scale + increment\n",
        "            if scale > 100:\n",
        "                result += current\n",
        "                current = 0\n",
        "\n",
        "    return (result + current,flag)\n",
        "\n",
        "\n",
        "def convert_to_lower(sentence):\n",
        "    return sentence.lower()\n",
        "\n",
        "def pre_process_sentence(sentence):\n",
        "    sentence=convert_to_lower(sentence)\n",
        "    sentence=sentence.strip()\n",
        "    sentence=sentence.replace(\"twice\",\"2 times\")\n",
        "    sentence=sentence.replace(\"thrice\",\"3 times\")\n",
        "    sentence1=\"\"\n",
        "    \n",
        "    for word in sentence.split(' '):\n",
        "        #word=word.replace('-',' ')\n",
        "        #print(text2int(word))\n",
        "        tmp_sentence,flag=text2int(word)\n",
        "        sentence1+=str(tmp_sentence)+\" \"\n",
        "        if(flag):\n",
        "            word=word.split(' ')\n",
        "            if(len(word)>1):\n",
        "                sentence1+=pre_process_sentence(\"\".join([str(elem) for elem in word[1:]]))\n",
        "\n",
        "    sentence=sentence1\n",
        "    sentence=sentence.replace(',', '')\n",
        "    sentence=re.sub(\"[A-Za-z\\-:()]+\", lambda ele: \" \" + ele[0] + \" \", sentence)\n",
        "    return sentence\n",
        "def evaluate_dataset():\n",
        "  correct_ans=0\n",
        "  total_ans=0\n",
        "  idx=0\n",
        "  normal_correct=0\n",
        "  total_correct=0\n",
        "  except_cnt=0\n",
        "  for q in range(len(normal_questions_eval)):\n",
        "    \n",
        "    idx+=1\n",
        "    #print(idx)\n",
        "    if idx % 10 == 0 :\n",
        "      #print(\"sadsadsad\")\n",
        "      print(except_cnt)\n",
        "      print(correct_ans/total_ans)\n",
        "      print(normal_correct/total_correct)\n",
        "    normal_sentence=pre_process_sentence(normal_questions_eval[q])\n",
        "    normal_sentence_lst=normal_sentence.split(' ')\n",
        "    \n",
        "    # print(prepared_questions_eval[q])\n",
        "    prepared_sentence_lst=prepared_questions_eval[q].split(' ')\n",
        "    \n",
        "    mapping_dict=dict()\n",
        "    #finding_idx=0\n",
        "    predicted_tmp=list()\n",
        "    for elem in normal_sentence_lst:\n",
        "      #print(elem)\n",
        "      if len(elem)!=0:\n",
        "        if elem[-1]==\"%\":\n",
        "          #print(elem[:-1])\n",
        "          predicted_tmp.append(elem[:-1])\n",
        "          predicted_tmp.append(\"%\")\n",
        "        else:\n",
        "          predicted_tmp.append(elem)\n",
        "      else:\n",
        "        predicted_tmp.append(elem)\n",
        "    \n",
        "    normal_sentence_lst=predicted_tmp\n",
        "    #print(normal_sentence_lst)\n",
        "    #print(prepared_sentence_lst)\n",
        "    for k in range(len(normal_sentence_lst)):\n",
        "      if normal_sentence_lst[k] != prepared_sentence_lst[k]:\n",
        "        mapping_dict[prepared_sentence_lst[k]]=normal_sentence_lst[k]\n",
        "    #print(mapping_dict)\n",
        "    predicted_prefix=predicted_eqn(prepared_questions_eval[q])\n",
        "    #print(predicted_prefix)\n",
        "    \n",
        "    #print(predicted_prefix)\n",
        "    #print(prefix_equations_list_eval[q])\n",
        "    for j in range(len(predicted_prefix)):\n",
        "\n",
        "      if j<len(prefix_equations_list_eval[q]) and predicted_prefix[j]==prefix_equations_list_eval[q][j]:\n",
        "        normal_correct+=1\n",
        "    total_correct+=len(predicted_prefix)\n",
        "    \n",
        "    predicted_prefix_temp=list()\n",
        "    for elem in predicted_prefix:\n",
        "      if (elem in mapping_dict.keys()):\n",
        "        predicted_prefix_temp.append(mapping_dict[elem])\n",
        "      else:\n",
        "        predicted_prefix_temp.append(elem)\n",
        "    predicted_prefix=predicted_prefix_temp\n",
        "    \n",
        "    #print(predicted_prefix)\n",
        "   \n",
        "    # for elem in predicted_prefix:\n",
        "    #   print(elem)\n",
        "    #   if len(elem)!=0:\n",
        "    #     if elem[-1]==\"%\":\n",
        "    #       predicted_tmp.append(elem[:-1])\n",
        "    #     else:\n",
        "    #       predicted_tmp.append(elem)\n",
        "    #   else:\n",
        "    #     predicted_tmp.append(elem)\n",
        "\n",
        "    #predicted_prefix=predicted_tmp\n",
        "    #print(predicted_prefix)\n",
        "    \n",
        "      \n",
        "    \n",
        "    try:\n",
        "\n",
        "      predicted_ans=evaluate_prefix(predicted_prefix)\n",
        "      if abs(predicted_ans-float(answers[q]))<0.005:\n",
        "        correct_ans+=1\n",
        "      total_ans+=1\n",
        "    except:\n",
        "      except_cnt+=1\n",
        "      total_ans+=1\n",
        "    print(\"Predicted Answer=\",predicted_ans,\"Expected Answer=\",answers[q])\n",
        "    \n",
        "  return float(correct_ans/total_ans)\n",
        "print(\"asasdsa\")\n",
        "print(evaluate_dataset())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "asasdsa\n",
            "Predicted Answer= -11.0 Expected Answer= 20\n",
            "Predicted Answer= 72686.0 Expected Answer= 1466\n",
            "Predicted Answer= 72686.0 Expected Answer= 180\n",
            "Predicted Answer= 32.0 Expected Answer= 32\n",
            "Predicted Answer= 39.76 Expected Answer= 39.76\n",
            "Predicted Answer= 3.999999999999999 Expected Answer= 4\n",
            "Predicted Answer= -0.1 Expected Answer= 10%\n",
            "Predicted Answer= 42.0 Expected Answer= 105\n",
            "Predicted Answer= 1764.0 Expected Answer= 2304\n",
            "2\n",
            "0.3333333333333333\n",
            "0.5961538461538461\n",
            "Predicted Answer= 19.625 Expected Answer= 12.5\n",
            "Predicted Answer= 47.770334928229666 Expected Answer= 39\n",
            "Predicted Answer= 0.10491071428571429 Expected Answer= 40\n",
            "Predicted Answer= 10842480.0 Expected Answer= 158\n",
            "Predicted Answer= 11.0 Expected Answer= 11\n",
            "Predicted Answer= 85.0 Expected Answer= 85\n",
            "Predicted Answer= 4500002.0 Expected Answer= 8000\n",
            "Predicted Answer= 4500002.0 Expected Answer= 65\n",
            "Predicted Answer= 39.285714285714285 Expected Answer= 6.93\n",
            "Predicted Answer= 43.0 Expected Answer= 43\n",
            "3\n",
            "0.3157894736842105\n",
            "0.5504587155963303\n",
            "Predicted Answer= 200.0 Expected Answer= 6\n",
            "Predicted Answer= 0.21428571428571427 Expected Answer= 15\n",
            "Predicted Answer= 66.85714285714286 Expected Answer= 117\n",
            "Predicted Answer= -10.181818181818182 Expected Answer= 100\n",
            "Predicted Answer= -10.0 Expected Answer= 650\n",
            "Predicted Answer= 0.72 Expected Answer= 0.72\n",
            "Predicted Answer= 1800.0 Expected Answer= 1800\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-8cc669134877>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    155\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect_ans\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal_ans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"asasdsa\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-63-8cc669134877>\u001b[0m in \u001b[0;36mevaluate_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mmapping_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprepared_sentence_lst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormal_sentence_lst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;31m#print(mapping_dict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0mpredicted_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredicted_eqn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepared_questions_eval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0;31m#print(predicted_prefix)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-c888626adb8b>\u001b[0m in \u001b[0;36mpredicted_eqn\u001b[0;34m(inp_sentence_words)\u001b[0m\n\u001b[1;32m     22\u001b[0m                                                   \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                                                   \u001b[0mcombined_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                                                   dec_padding_mask)\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mpredicted_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-121598707c5c>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Pass the input to the encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0menc_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Pass the encoder output to the decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-949883ee92cc>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, training, mask)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-ae2c59e39a3c>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, training, mask)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Multi-head attention layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;31m# add residual connection to avoid vanishing gradient problem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mout1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayernorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1019\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_save_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_functional_construction_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpi8JaiblDOh"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Op5A3ikpil_l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wghgw0kyYbNQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myLyxXYpiltz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiVDtj2FoNZr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joZ3POuph8NH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHXS6bCHo8r7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spiU0QDI2egM"
      },
      "source": [
        "### Get Accuracy and Corpus BLEU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIQBWfa03ujc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTs5Q4Qf2qNv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVyDC8zyo0uM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Glj16cyQ7FJe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daGaIvQW7riI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcswXaKS5ssh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SFJifWj7AtQ"
      },
      "source": [
        "#### Translation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEmx2HVO6_cC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_fyWhFZ6_cG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fPqedk46_cM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Pm4N7Xo6_cN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4zBzmcq6_cP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUVJbPnJ6_cV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFbRPr916_cY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQOswvCM6_cZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6ERVfc2FKJ8"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPktUoq4FKFw"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6hEzg8iunje"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}