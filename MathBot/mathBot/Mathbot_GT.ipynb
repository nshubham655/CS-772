{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Mathbot_GT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzFGQDq_eQhq",
        "outputId": "f4578c2b-59d9-4560-de26-91edfe4e0a48"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYCsVSqCmxrG"
      },
      "source": [
        "<h1> Import Libraries Here </h1>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxTFbysWm-t1"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from nltk.corpus import stopwords  \n",
        "from nltk.tokenize import word_tokenize  \n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing import sequence\n",
        "import copy\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMLSLbdIorIy"
      },
      "source": [
        "<h1> Read Training Data Here </h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbkJoeVzou7V"
      },
      "source": [
        "prepared_dataset=pd.read_csv('/content/drive/MyDrive/Math23K_English_with_data_prep.csv')\n",
        "#prepared_dataset.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KWR8UdVq78w"
      },
      "source": [
        "with open('/content/drive/MyDrive/equations_data.json') as f:\n",
        "  prefix_equations_list = json.load(f)\n",
        "#print(len(prefix_equations_list))\n",
        "#print(prefix_equations_list[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Cz0d6iqpvbp"
      },
      "source": [
        "<h1> Extract Parts Of Prepared Dataset Here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXllcE3Ppd2N"
      },
      "source": [
        "prepared_questions=prepared_dataset['prepared_question'].values.tolist()\n",
        "#print(len(prepared_questions))\n",
        "#print(prepared_questions[0])   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qW0aiWjp_A5"
      },
      "source": [
        "normal_questions=prepared_dataset['segmented_question'].values.tolist()\n",
        "#print(len(normal_questions))\n",
        "#print(normal_questions[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geyzCUzJqb8Z"
      },
      "source": [
        "infix_equations=prepared_dataset['equation'].values.tolist()\n",
        "#print(len(infix_equations))\n",
        "#print(infix_equations[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvp2L1s9qm7N"
      },
      "source": [
        "answers=prepared_dataset['ans'].values.tolist()\n",
        "#print(len(answers))\n",
        "#print(answers[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81DDoSR4dwgO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_m3DTVtrnk-"
      },
      "source": [
        "<h1> Preprocess The Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkW6lrnxMiFH"
      },
      "source": [
        "<h2> Remove the unnecessary Data (No Prefix) </h2> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7IHnImgS4UC",
        "outputId": "136e77cb-006d-4b4e-e6f5-319c6cc80c8c"
      },
      "source": [
        "idx_to_remove=[i for i in range(len(prefix_equations_list)) if prefix_equations_list[i]==\"no_prefix\"]\n",
        "prepared_questions=[prepared_questions[i] for i in range(len(prefix_equations_list)) if prefix_equations_list[i] != \"no_prefix\"]\n",
        "normal_questions=[normal_questions[i] for i in range(len(prefix_equations_list)) if prefix_equations_list[i] != \"no_prefix\"]\n",
        "infix_equations=[infix_equations[i] for i in range(len(prefix_equations_list)) if prefix_equations_list[i] != \"no_prefix\"]\n",
        "answers=[answers[i] for i in range(len(prefix_equations_list)) if prefix_equations_list[i] != \"no_prefix\"]\n",
        "prefix_equations_list=[equation for equation in prefix_equations_list if equation != \"no_prefix\"]\n",
        "\n",
        "\n",
        "idx_to_remove_chinnese=[i for i in range(len(infix_equations)) if infix_equations[i]==\"x=80千米/小时\"]\n",
        "print(idx_to_remove_chinnese)\n",
        "if len(idx_to_remove_chinnese) >=1:\n",
        "  prepared_questions.pop(idx_to_remove_chinnese[0])\n",
        "  normal_questions.pop(idx_to_remove_chinnese[0])\n",
        "  infix_equations.pop(idx_to_remove_chinnese[0])\n",
        "  answers.pop(idx_to_remove_chinnese[0])\n",
        "  prefix_equations_list.pop(idx_to_remove_chinnese[0])\n",
        "\n",
        "# print(len(idx_to_remove))\n",
        "# print(idx_to_remove)\n",
        "# print(len(prefix_equations_list))\n",
        "# print(len(prepared_questions))\n",
        "# print(len(normal_questions)) \n",
        "# print(len(infix_equations))\n",
        "# print(len(answers))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[10149]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3N3-65lT425"
      },
      "source": [
        "# print(prefix_equations_list[2578])\n",
        "# print(prepared_questions[2578])\n",
        "# print(normal_questions[2578])\n",
        "# print(infix_equations[2578])\n",
        "# print(answers[2578])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ccJ9MeXr93B"
      },
      "source": [
        "<h2> Tokenize  </h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESIpJmsoqt15",
        "outputId": "ec48bdb6-e4a8-4065-e61c-220b8b130603"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMbR11uLsA94"
      },
      "source": [
        "temp_questions=list()\n",
        "for elem in prepared_questions:\n",
        "  temp_questions.append(word_tokenize(elem))\n",
        "prepared_questions=temp_questions\n",
        "#print(len(prepared_questions))\n",
        "# print(prepared_questions[0])\n",
        "# print(prepared_questions[0].index('n0'))\n",
        "# print(prepared_questions[0].index('n1'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rO7JSUkYEUZC"
      },
      "source": [
        "<h1> Making Dict of Indexes of Unknowns (n's)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQcYQ23aEb7K",
        "outputId": "76ae38f7-3353-4155-d9d4-5979464c7ee1"
      },
      "source": [
        "unknown_dict_structure={'n0':-1,'n1':-1,'n2':-1,'n3':-1, 'n4': -1,'n5': -1,'n6': -1,'n7': -1,'n8': -1,'n9': -1,'n10': -1,'n11': -1,'n13': -1,'n15': -1}\n",
        "unknowns_dict_list=[unknown_dict_structure.copy() for elem in prepared_questions]\n",
        "unknowns_lst=unknown_dict_structure.keys()\n",
        "# print(len(unknowns_lst))\n",
        "unknowns_lst=list(unknowns_lst)\n",
        "print(unknowns_lst)\n",
        "# print(len(unknowns_dict_list))\n",
        "# print(len(prepared_questions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['n0', 'n1', 'n2', 'n3', 'n4', 'n5', 'n6', 'n7', 'n8', 'n9', 'n10', 'n11', 'n13', 'n15']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owcePU8ZFCZT"
      },
      "source": [
        "for q in range(len(prepared_questions)):\n",
        "  for w in range(len(prepared_questions[q])):\n",
        "    # print(prepared_questions[q][w])\n",
        "    # harsh_exit()\n",
        "    # break\n",
        "    if prepared_questions[q][w] in unknowns_lst:\n",
        "      # print(prepared_questions[q][w])\n",
        "      # print(w)\n",
        "      # harsh_exit()\n",
        "      #print(prepared_questions[q][w])\n",
        "\n",
        "      unknowns_dict_list[q][prepared_questions[q][w]]=w\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r26RqFlqMyfu"
      },
      "source": [
        "# print(unknowns_dict_list[0])\n",
        "# print(unknowns_dict_list[1])\n",
        "# print(unknowns_dict_list[2])\n",
        "\n",
        "# print(prepared_questions[1])\n",
        "# # print(prepared_questions[2])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75ifyQW6tUIj"
      },
      "source": [
        "<h1> Create Vocab Input and Output Both</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tocVR88B0a8X"
      },
      "source": [
        "index_to_word_input=['<pad>']\n",
        "for question in prepared_questions:\n",
        "  for word in question:\n",
        "    if(word not in index_to_word_input):\n",
        "      index_to_word_input.append(word)\n",
        "#print(len(index_to_word_input))\n",
        "#print(index_to_word_input[0])\n",
        "index_to_word_input.append('<start>')\n",
        "index_to_word_input.append('<end>')\n",
        "input_vocab_size=len(index_to_word_input)\n",
        "#input_vocab_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTF1uNI00CN0"
      },
      "source": [
        "word_to_index_input={'<pad>':0}\n",
        "for word in index_to_word_input:\n",
        "  if word not in word_to_index_input.keys():\n",
        "    word_to_index_input[word]=index_to_word_input.index(word)\n",
        "# print(len(word_to_index_input))\n",
        "# print(word_to_index_input[\"n0\"])\n",
        "# print(word_to_index_input[\"n1\"])\n",
        "# print(word_to_index_input[\"children\"])\n",
        "# print(word_to_index_input['<pad>'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iakcke7Zs4Zh"
      },
      "source": [
        "index_to_word_output=list()\n",
        "for equation in prefix_equations_list:\n",
        "  for elem in equation:\n",
        "    if elem not in index_to_word_output:\n",
        "      index_to_word_output.append(elem)\n",
        "# print(len(index_to_word_output))\n",
        "# print(index_to_word_output[0])\n",
        "index_to_word_output.append('<start>')\n",
        "index_to_word_output.append('<end>')\n",
        "output_vocab_size=len(index_to_word_output)\n",
        "# print(output_vocab_size)\n",
        "# print(index_to_word_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4Re5mAJtbGH"
      },
      "source": [
        "word_to_index_output=dict()\n",
        "for word in index_to_word_output:\n",
        "  if word not in word_to_index_output.keys():\n",
        "    word_to_index_output[word]=index_to_word_output.index(word)\n",
        "# print(len(word_to_index_output))\n",
        "# print(word_to_index_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHPTTFziZ97D"
      },
      "source": [
        "<h1> Encode Data </h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AIg1FFQ3qsu"
      },
      "source": [
        "prepared_questions_temp=list()\n",
        "for question in prepared_questions:\n",
        "  question_temp=list()\n",
        "  for word in question:\n",
        "    question_temp.append(word_to_index_input[word])\n",
        "  prepared_questions_temp.append(question_temp)\n",
        "# print(prepared_questions[11235])\n",
        "prepared_questions=prepared_questions_temp\n",
        "# print(prepared_questions[11235])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-0OdYhvUxlX",
        "outputId": "21f06495-b12e-4cd7-8e70-a38b2d5a6503"
      },
      "source": [
        "print(prepared_questions[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 10, 4, 11, 12, 13, 9, 14, 15, 16, 1, 3, 17, 11, 18, 19, 20, 21, 22, 15, 23, 17, 24, 25, 26, 4, 1, 13, 27, 28, 29, 30, 31, 11, 32, 4, 33, 15, 23, 17, 16, 34, 35, 21, 36, 37, 38, 39]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OT-oHTKKcD6D"
      },
      "source": [
        "<h1> Padding </h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhbPfmofa1mC"
      },
      "source": [
        "max_len=max(len(question) for question in prepared_questions)\n",
        "#print(max_len)\n",
        "prepared_questions= sequence.pad_sequences(prepared_questions, maxlen=max_len,padding=\"post\")\n",
        "# print(prepared_questions[2])\n",
        "# print(len(prepared_questions))\n",
        "#reviews.shape\n",
        "# print(prepared_questions[0])\n",
        "# print(prepared_questions[0].index(20))\n",
        "# print(prepared_questions[0].index(33))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJjSAJR5VWzT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKo2p99jDIri"
      },
      "source": [
        "# print(word_to_index_input['n0'])\n",
        "# print(word_to_index_input['n1'])\n",
        "# print(torch.tensor(prepared_questions).shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4TGAcLmf1Fx"
      },
      "source": [
        "<h1> Import Pytorch Dependencies Here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKO8f7KNf4T3"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset,DataLoader \n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.sampler import WeightedRandomSampler\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjlWdr1Zf90n"
      },
      "source": [
        "<h1> Split Data into Train and Validation and Test</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvpzBzPUgA6l"
      },
      "source": [
        "prepared_questions_train, prepared_questions_test, prefix_equations_list_train, prefix_equations_list_test = train_test_split(prepared_questions,prefix_equations_list, train_size=0.9)\n",
        "# print(len(prepared_questions_train))\n",
        "# print(len(prefix_equations_list_train))\n",
        "# print(len(prepared_questions_test))\n",
        "# print(len(prefix_equations_list_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz9HFaIVgelm"
      },
      "source": [
        "prepared_questions_train, prepared_questions_val, prefix_equations_list_train, prefix_equations_list_val = train_test_split(prepared_questions_train,prefix_equations_list_train, train_size=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYUhIgWnhG4_"
      },
      "source": [
        "# print(len(prepared_questions_train))\n",
        "# print(len(prefix_equations_list_train))\n",
        "# print(len(prepared_questions_val))\n",
        "# print(len(prefix_equations_list_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIk9_ZW6rV4s"
      },
      "source": [
        "<h1> Encoder </h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OYMNS7ofEm7"
      },
      "source": [
        "class Encoder_GT(torch.nn.Module):\n",
        "  def __init__(self,input_vocab_size,embedding_dim,hidden_dim):\n",
        "    super().__init__()\n",
        "    self.hidden_dim=hidden_dim\n",
        "    self.embedding=nn.Embedding(input_vocab_size+1,embedding_dim,padding_idx=0)\n",
        "    self.bigru=nn.GRU(embedding_dim,hidden_dim,batch_first=True,bidirectional=True)\n",
        "    self.dropout=nn.Dropout()\n",
        "  \n",
        "  def forward(self,question):\n",
        "    h0=torch.zeros(1,question.size(0),self.hidden_dim)\n",
        "    embedded_question=self.embedding(question)\n",
        "    #print(embedded_question)\n",
        "    embedded_question_dropout=self.dropout(embedded_question)\n",
        "    #print(embedded_question_dropout)\n",
        "    gru_rep,(hidden1,hidden2)=self.bigru(embedded_question_dropout)\n",
        "    #print(gru_rep)\n",
        "    gru_rep=gru_rep[:, :, :self.hidden_dim] +gru_rep[:, :, self.hidden_dim:]\n",
        "    #print(\"-------------------------------\")\n",
        "    #print(gru_rep)\n",
        "    #print(hidden1)\n",
        "    #print(hidden2)\n",
        "    return hidden1+hidden2,gru_rep\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5-FXBZ_msz-"
      },
      "source": [
        "# encoder_model=Encoder_GT(input_vocab_size,5,4)\n",
        "# question=[[1,25,3],[25,2,45]]\n",
        "# unknowns=[{'n0':1,'n1':-1,'n2':-1}],{'n0':0,'n1':2,'n2':-1}\n",
        "# goal,gru_rep=encoder_model(torch.tensor(question))\n",
        "# print(gru_rep)\n",
        "# print(gru_rep[0][1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DUKjr7mOIwb",
        "outputId": "14e4c2ce-1106-4901-9db9-a92d4ba18ef4"
      },
      "source": [
        "word_to_index_output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'*': 0,\n",
              " '+': 5,\n",
              " '-': 1,\n",
              " '/': 7,\n",
              " '0': 17,\n",
              " '1': 3,\n",
              " '2': 19,\n",
              " '3': 14,\n",
              " '4': 18,\n",
              " '5': 16,\n",
              " '6': 15,\n",
              " '7': 11,\n",
              " '8': 20,\n",
              " '9': 22,\n",
              " '<end>': 30,\n",
              " '<start>': 29,\n",
              " '^': 21,\n",
              " 'n0': 4,\n",
              " 'n1': 2,\n",
              " 'n10': 25,\n",
              " 'n11': 26,\n",
              " 'n13': 27,\n",
              " 'n15': 28,\n",
              " 'n2': 6,\n",
              " 'n3': 9,\n",
              " 'n4': 8,\n",
              " 'n5': 12,\n",
              " 'n6': 10,\n",
              " 'n7': 13,\n",
              " 'n8': 23,\n",
              " 'n9': 24}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDJOFM7xPS19",
        "outputId": "3b1a3055-a9c7-4a02-e04b-e1d4e0bd69cc"
      },
      "source": [
        "output_vocab_only_n={'n0':4,'n1':2,'n2':6,'n3':9, 'n4': 8,'n5': 12,'n6': 10,'n7': 13,'n8': 23,'n9': 24,'n10': 25,'n11': 26,'n13': 27,'n15': 28}\n",
        "output_vocab_only_operators={'*':0,'+':5,'-':1,'/':7,'^':21}\n",
        "output_vocab_only_constants={'0':17,'1':3,'2':19,'3':14,'4':18,'5':16,'6':15,'7':11,'8':20,'9':22}\n",
        "word_to_index_output_loss=dict()\n",
        "idx=0\n",
        "for operator in output_vocab_only_operators.keys():\n",
        "  word_to_index_output_loss[operator]=idx\n",
        "  idx+=1\n",
        "\n",
        "for operator in output_vocab_only_constants.keys():\n",
        "  word_to_index_output_loss[operator]=idx\n",
        "  idx+=1\n",
        "\n",
        "for operator in output_vocab_only_n.keys():\n",
        "  word_to_index_output_loss[operator]=idx\n",
        "  idx+=1\n",
        "\n",
        "print(word_to_index_output_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'*': 0, '+': 1, '-': 2, '/': 3, '^': 4, '0': 5, '1': 6, '2': 7, '3': 8, '4': 9, '5': 10, '6': 11, '7': 12, '8': 13, '9': 14, 'n0': 15, 'n1': 16, 'n2': 17, 'n3': 18, 'n4': 19, 'n5': 20, 'n6': 21, 'n7': 22, 'n8': 23, 'n9': 24, 'n10': 25, 'n11': 26, 'n13': 27, 'n15': 28}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-N38WsJlrU0E"
      },
      "source": [
        "<h1> Decoder </h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2acfpawUQIP",
        "outputId": "c018ab87-e456-4e8d-f86c-98f7e4007aa9"
      },
      "source": [
        "print(torch.tensor(prepared_questions).shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([22485, 135])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsMlYwc2SL8X"
      },
      "source": [
        "# q=torch.tensor([[[1,2,3,9,10,11,12,14]],[[4,5,6,90,80,34,67,54]]])\n",
        "# rep=torch.tensor([[[7,8,10,11],[17,18,110,111],[71,81,101,111]],[[72,82,102,112],[217,218,2110,2111],[731,831,1301,1311]]])\n",
        "# print(q.shape)\n",
        "# print(rep.shape)\n",
        "# print(torch.tile(q,(1,3,1)))\n",
        "# q=torch.tile(q,(1,3,1))\n",
        "# print(torch.tile(q,(1,3,1)).shape)\n",
        "# print(torch.cat((q,rep),2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCslFmTXOs9R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LISLp1ouQMU9"
      },
      "source": [
        "class Attention_Block(torch.nn.Module):\n",
        "  def __init__(self,hidden_dim):\n",
        "    super().__init__()\n",
        "    self.hidden_dim=hidden_dim\n",
        "    self.linear_1=nn.Linear(2*hidden_dim,hidden_dim,bias=False)\n",
        "    self.tanh=nn.Tanh()\n",
        "    self.linear_2=nn.Linear(hidden_dim,1,bias=False)\n",
        "    self.softmax=nn.Softmax(dim=1)\n",
        "\n",
        "  def forward(self,goal,all_rep):\n",
        "    #Convert Goal into required dimension (n*w*2d) than concat is possible\n",
        "    # May be deep copy (n*d), (n*w*d) ,(n*w*d) \n",
        "    goal=torch.tile(torch.reshape(goal,(goal.shape[0],1,goal.shape[1])),(1,max_len,1))\n",
        "    #print(goal.shape)\n",
        "    #print(all_rep)\n",
        "    input_vector=torch.cat((goal,all_rep),2)\n",
        "    #print(input_vector.shape)\n",
        "    x=self.linear_1(input_vector)\n",
        "    x=self.tanh(x)\n",
        "    scores=self.linear_2(x)\n",
        "    #print(scores)\n",
        "    #print(scores.shape)\n",
        "    weights=self.softmax(scores)\n",
        "    #print(weights)\n",
        "    #print(weights)\n",
        "    \n",
        "    #\n",
        "    ctx_vector=torch.einsum('nwd,nwe->nd',all_rep,weights)\n",
        "    # print(ctx_vector)\n",
        "    # print(ctx_vector.shape)\n",
        "\n",
        "    return ctx_vector\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZLKep3qZ2E_"
      },
      "source": [
        "# test_attention=Attention_Block(4)\n",
        "# q=torch.tensor([[1.0,2.0,3.0,9.0],[4.0,5.0,6.0,90.0]])\n",
        "# rep=torch.tensor([[[7.0,8.0,10.0,11.0],[17.0,18.0,110.0,111.0],[71.0,81.0,101.0,111.0]],[[72.0,82.0,102.0,112.0],[217.0,218.0,2110.0,2111.0],[731.0,831.0,1301.0,1311.0]]])\n",
        "# print(q.shape)\n",
        "# print(rep.shape)\n",
        "# test_attention(q,rep).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0mhfV7LhFnM"
      },
      "source": [
        "# weights=[[[1],[2],[3]],[[5],[6],[7]]]\n",
        "# all_rep=[[[5,6],[7,8],[9,10]],[[12,13],[15,16],[1,1]]]\n",
        "# print(torch.tensor(all_rep))\n",
        "# print(torch.tensor(weights))\n",
        "# torch.einsum('nwd,nwe->nd',torch.tensor(all_rep),torch.tensor(weights))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OYjZ-yj1D_P"
      },
      "source": [
        "class Test(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.embedding_operator=nn.Embedding(output_vocab_size,4,padding_idx=0)\n",
        "    self.softmax=nn.Softmax()\n",
        "  def forward(self,x):\n",
        "    return self.softmax(self.embedding_operator(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAnTl4Jk1rwr",
        "outputId": "bdd90075-1d88-48ee-e04b-a17b96592e1c"
      },
      "source": [
        "test=Test()\n",
        "test(torch.tensor([0]))[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2500, 0.2500, 0.2500, 0.2500], grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3elijYrraac"
      },
      "source": [
        "class Decoder_GT(torch.nn.Module):\n",
        "  def __init__(self,hidden_dim):\n",
        "    super().__init__()\n",
        "    self.embedding_operator=nn.Embedding(output_vocab_size,hidden_dim)\n",
        "    self.embedding_constants=nn.Embedding(output_vocab_size,hidden_dim)\n",
        "    self.linear=nn.Linear(hidden_dim+2*hidden_dim,hidden_dim,bias=False)\n",
        "    self.linear_1=nn.Linear(hidden_dim,1,bias=False)\n",
        "    self.linear_sig=nn.Linear(3*hidden_dim,hidden_dim,bias=False)\n",
        "    self.linear_sig_right=nn.Linear(3*hidden_dim,hidden_dim,bias=False)\n",
        "    self.sigmoid=nn.Sigmoid()\n",
        "    self.linear_tanh=nn.Linear(3*hidden_dim,hidden_dim,bias=False)\n",
        "    self.linear_sig_child=nn.Linear(hidden_dim,hidden_dim,bias=False)\n",
        "    self.linear_tanh_child=nn.Linear(hidden_dim,hidden_dim,bias=False)\n",
        "    self.linear_tanh_right=nn.Linear(3*hidden_dim,hidden_dim,bias=False)\n",
        "    self.linear_sig_child_right=nn.Linear(hidden_dim,hidden_dim,bias=False)\n",
        "    self.linear_tanh_child_right=nn.Linear(hidden_dim,hidden_dim,bias=False)\n",
        "    self.tanh=nn.Tanh()\n",
        "    self.hidden_dim=hidden_dim\n",
        "    self.attention=Attention_Block(hidden_dim)\n",
        "    self.softmax=nn.Softmax()\n",
        "\n",
        "  def forward(self,goal_parent,ctx_vector_parent,all_rep,unknowns_list_dict,output_vocab_only_operators,output_vocab_only_constants,token_embedding_parent,left_child=True,target=0,is_train=True,is_root=False,idx=0):\n",
        "    #Send The parent Operator here\n",
        "    #Dimension goal,ctx_vector n*d\n",
        "    #print(goal_parent)\n",
        "    if (is_root):\n",
        "      goal=goal_parent\n",
        "    else:\n",
        "      if left_child:\n",
        "\n",
        "        concat_interim=torch.cat((goal_parent,ctx_vector_parent),1)\n",
        "        final_cat=torch.cat((concat_interim,token_embedding_parent),1)\n",
        "        sig_out=self.sigmoid(self.linear_sig(final_cat))\n",
        "        tan_out=self.tanh(self.linear_tanh(final_cat))\n",
        "        sig_tan=torch.mul(sig_out,tan_out)\n",
        "        g_l=self.sigmoid(self.linear_sig_child(sig_tan))\n",
        "        q_le=self.tanh(self.linear_tanh_child(sig_tan))\n",
        "        goal=torch.mul(g_l,q_le)\n",
        "      \n",
        "      else:\n",
        "\n",
        "        concat_interim=torch.cat((goal_parent,ctx_vector_parent),1)\n",
        "        final_cat=torch.cat((concat_interim,token_embedding_parent),1)\n",
        "        sig_out=self.sigmoid(self.linear_sig_right(final_cat))\n",
        "        tan_out=self.tanh(self.linear_tanh_right(final_cat))\n",
        "        sig_tan=torch.mul(sig_out,tan_out)\n",
        "        g_l=self.sigmoid(self.linear_sig_child_right(sig_tan))\n",
        "        q_le=self.tanh(self.linear_tanh_child_right(sig_tan))\n",
        "        goal=torch.mul(g_l,q_le)\n",
        "\n",
        "      #print(goal)\n",
        "\n",
        "      # goal=calculat_root_goal()\n",
        "\n",
        "    ctx_vector=self.attention(goal,all_rep)\n",
        "    #print(ctx_vector)\n",
        "    if is_root:\n",
        "\n",
        "      with torch.no_grad():\n",
        "        for elem in unknowns_list_dict.keys():\n",
        "          if unknowns_list_dict[elem] != -1:\n",
        "            unknowns_list_dict[elem]=copy.deepcopy(all_rep[0][unknowns_list_dict[elem]])\n",
        "            \n",
        "          else:\n",
        "            unknowns_list_dict[elem]=torch.tensor([0 for i in range(self.hidden_dim)])\n",
        "        #print(unknowns_list_dict)\n",
        "\n",
        "    inp_list=list() #MAY BE PROBLEMATIC IN BACKPROP\n",
        "\n",
        "    for operator in output_vocab_only_operators.keys():\n",
        "      operator_emb=self.embedding_operator(torch.tensor([output_vocab_only_operators[operator]]))\n",
        "      concat_goal_ctx=torch.cat((goal,ctx_vector),1)\n",
        "      # print(concat_goal_ctx.shape)\n",
        "      # print(operator_emb.shape)\n",
        "      final_concat=torch.cat((concat_goal_ctx,operator_emb),1)\n",
        "      interim=self.linear(final_concat)\n",
        "      interim=self.tanh(interim)\n",
        "      interim=self.linear_1(interim)\n",
        "      inp_list.append(interim)\n",
        "    \n",
        "    for constant in output_vocab_only_constants.keys():\n",
        "      constant_emb=self.embedding_constants(torch.tensor([output_vocab_only_constants[constant]]))\n",
        "      # print(constant_emb)\n",
        "      # harsh_exit()\n",
        "      concat_goal_ctx=torch.cat((goal,ctx_vector),1)\n",
        "      final_concat=torch.cat((concat_goal_ctx,constant_emb),1)\n",
        "      interim=self.linear(final_concat)\n",
        "      interim=self.tanh(interim)\n",
        "      interim=self.linear_1(interim)\n",
        "      inp_list.append(interim)\n",
        "    \n",
        "    for unknown_embedding in unknowns_list_dict.values():\n",
        "      concat_goal_ctx=torch.cat((goal,ctx_vector),1)\n",
        "      #print(unknown_embedding.shape)\n",
        "      final_concat=torch.cat((concat_goal_ctx,torch.unsqueeze(unknown_embedding, 0)),1)\n",
        "      interim=self.linear(final_concat)\n",
        "      interim=self.tanh(interim)\n",
        "      interim=self.linear_1(interim)\n",
        "      inp_list.append(interim)\n",
        "    #print(inp_list)\n",
        "    #May be problematic in backprop check this first\n",
        "    out_tensor=inp_list[0]\n",
        "    \n",
        "    for k in range(len(inp_list)):\n",
        "      if k!=0:\n",
        "        out_tensor=torch.cat((out_tensor,inp_list[k]),1)\n",
        "    #print(out_tensor)\n",
        "    prob_y=self.softmax(out_tensor)\n",
        "    # print(idx)\n",
        "    #print(prob_y)\n",
        "    #print(prob_y.shape)\n",
        "    # print(target[idx])\n",
        "    if is_train:\n",
        "\n",
        "      if target[idx] in output_vocab_only_operators.keys():\n",
        "        ret_list=prob_y\n",
        "        left_append,l_idx=self.forward(goal,ctx_vector,all_rep,unknowns_list_dict,output_vocab_only_operators,output_vocab_only_constants,self.embedding_operator(torch.tensor([output_vocab_only_operators[target[idx]]])),True,target,True,False,idx+1)\n",
        "        ret_list=torch.cat((ret_list,left_append),0)\n",
        "        \n",
        "        right_append,r_idx=self.forward(goal,ctx_vector,all_rep,unknowns_list_dict,output_vocab_only_operators,output_vocab_only_constants,self.embedding_operator(torch.tensor([output_vocab_only_operators[target[idx]]])),False,target,True,False,l_idx+1)       \n",
        "        ret_list=torch.cat((ret_list,right_append),0)\n",
        "        \n",
        "        return ret_list,r_idx\n",
        "      else:\n",
        "        return prob_y,idx\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pf3CVPHd6mYa"
      },
      "source": [
        "# encoder_model=Encoder_GT(input_vocab_size,5,4)\n",
        "# question=[[1,25,3]]\n",
        "# unknowns=[{'n0':1,'n1':-1,'n2':-1,'n3':-1}]\n",
        "# goal,gru_rep=encoder_model(torch.tensor(question))\n",
        "# # print(gru_rep)\n",
        "# # print(gru_rep[0][1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZER_cR152pe"
      },
      "source": [
        "\n",
        "# ctx_vector=torch.tensor([[0,0,0,0]])\n",
        "\n",
        "# decoder=Decoder_GT(4)\n",
        "# decoder(goal,ctx_vector,gru_rep,unknowns[0],output_vocab_only_operators,output_vocab_only_constants,0,False,[\"*\",\"+\",\"n0\",\"*\",\"n1\",\"n2\",\"n3\"],True,True,0)\n",
        "# #(goal,ctx_vector,all_rep,unknowns_list_dict,output_vocab_only_operators,output_vocab_only_constants,self.embedding_operator(torch.tensor([output_vocab_only_operators[target[idx]]])),True,target,True,False,idx+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY_A63ImQFlj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDaNGcc5Uv0n"
      },
      "source": [
        "<h1> Making Encoder-Decoder </h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyJ54wUfL6Vf"
      },
      "source": [
        "class encoder_decoder_GT(torch.nn.Module):\n",
        "  def __init__(self,input_vocab_size,embedding_dim,hidden_dim):\n",
        "    super().__init__()\n",
        "    self.encoder=Encoder_GT(input_vocab_size,embedding_dim,hidden_dim)\n",
        "    self.decoder=Decoder_GT(hidden_dim)\n",
        "  \n",
        "  def forward(self,questions,target,unknowns_dict):\n",
        "    #decoder(goal,ctx_vector,gru_rep,unknowns[0],output_vocab_only_operators,output_vocab_only_constants,0,False,[\"*\",\"+\",\"n0\",\"*\",\"n1\",\"n2\",\"n3\"],True,True,0)\n",
        "    root_goal,all_rep=self.encoder(questions)\n",
        "    #print(root_goal.shape)\n",
        "    #print(all_rep.shape)\n",
        "    #ctx_vect\n",
        "    return self.decoder(root_goal,0,all_rep,unknowns_dict,output_vocab_only_operators,output_vocab_only_constants,0,False,target,True,True,0)\n",
        "    \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0__PG1xUzbp"
      },
      "source": [
        "<h1>Making Data Loader</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMfKpz2kUzJD"
      },
      "source": [
        "class Math_Dataset(Dataset):\n",
        "  def __init__(self,Q,E,U):\n",
        "    #super().__init__()\n",
        "    self.Q=Q\n",
        "    self.E=E\n",
        "    self.U=U\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.Q)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    print(self.E[idx])\n",
        "    return torch.tensor(self.Q[idx]),self.E[idx],self.U[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h2twklQVfg-"
      },
      "source": [
        "train_ds=Math_Dataset(prepared_questions,prefix_equations_list,unknowns_dict_list)\n",
        "train_dl=DataLoader(train_ds,batch_size=1)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuhUigMvUvGY"
      },
      "source": [
        "<h1> Training The Model </h1>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpYFohxoVybR"
      },
      "source": [
        "def train(model,epochs=1000,lr=0.001):\n",
        "  # model.to(device)\n",
        "  parameters=filter(lambda p: p.requires_grad, model.parameters())\n",
        "  optimizer = torch.optim.Adam(parameters, lr=lr)\n",
        "  loss = nn.NLLLoss()\n",
        "\n",
        "\n",
        "  for epoch in range(0,epochs):\n",
        "    correct=0\n",
        "    total=0\n",
        "    sum_loss=0\n",
        "    idx_cnt=0\n",
        "    total_elem=0\n",
        "    model.train()\n",
        "    for idx in range(len(prepared_questions)):\n",
        "      q=torch.tensor([prepared_questions[idx]])\n",
        "      t=prefix_equations_list[idx]\n",
        "      u=copy.deepcopy(unknowns_dict_list[idx])\n",
        "      #print(idx)\n",
        "      e=list()\n",
        "      for elem in t:\n",
        "        e.append(word_to_index_output_loss[elem])\n",
        "      e=torch.tensor([e])\n",
        "      #predicted_ans,_=model(q,t,u)\n",
        "      #print(len(predicted_ans))\n",
        "      #print(len(predicted_ans[0]))\n",
        "      #print(predicted_ans)\n",
        "      # print(t)\n",
        "      # print(predicted_ans.shape)\n",
        "      # print(e[0].shape)\n",
        "      # print(e[0])\n",
        "      \n",
        "      if True:\n",
        "        #print(u)\n",
        "        predicted_ans,_=model(q,t,u)\n",
        "        optimizer.zero_grad()\n",
        "        if e[0].shape[0]==predicted_ans.shape[0]:\n",
        "          #print(predicted_ans.shape)\n",
        "          #print(e[0])\n",
        "          #print(predicted_ans)\n",
        "          \n",
        "          #print(predicted_ans.unsqueeze(0).shape)\n",
        "          #print(e[0].shape)\n",
        "          #print(e.shape)\n",
        "          output=0\n",
        "          \n",
        "          output+=loss(predicted_ans.unsqueeze(0)[0],e[0])\n",
        "          #print(output)\n",
        "          output.backward()\n",
        "          optimizer.step()\n",
        "          pred=torch.max(predicted_ans, 1)[1]\n",
        "          #print(pred)\n",
        "          #print(e[0])\n",
        "          for j in range(len(e[0])):\n",
        "            if e[0][j]==pred[j]:\n",
        "              correct+=1\n",
        "            total+=1\n",
        "        else:\n",
        "          idx_cnt+=1\n",
        "        #harsh_exit344()\n",
        "      # print(output)\n",
        "      # harsh_exit()\n",
        "      \n",
        "      if idx%1000==0:\n",
        "        print(\"Train Accuracy=\",(correct/(total)), \"data processed=\",idx)\n",
        "        print(pred)\n",
        "        #print(e[0])\n",
        "\n",
        "    if(epoch%1==0):\n",
        "      print(epoch,\"th Epoch, Train Accuracy=\",(correct/total),end=' ')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POQDcKxTWZyc"
      },
      "source": [
        "<h1> Making the Model </h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRsi2TtPWZjf"
      },
      "source": [
        "model=encoder_decoder_GT(input_vocab_size,200,250)\n",
        "\n",
        "train(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOpddo5mmFl5"
      },
      "source": [
        "def save_check_point(model,valid_loss=0):\n",
        "  #model.to(device)\n",
        "  #valid_loss.to(device)\n",
        "  state_dict={'model_state_dict':model.state_dict(),'valid_loss':valid_loss}\n",
        "  torch.save(state_dict,\"/content/drive/MyDrive/model_200d.pth\")\n",
        "  print(\"Model Check Point Saved Succesfully\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6XkL4u28MqC"
      },
      "source": [
        "print(prepared_questions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14smc1V9nIum"
      },
      "source": [
        "save_check_point(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqCFbFMU6U_4"
      },
      "source": [
        "print(prepared_questions[4403])\n",
        "print(prefix_equations_list[4403])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnMR5auLHTct"
      },
      "source": [
        "idx=0\n",
        "for name,_ in  model.named_parameters():\n",
        "  idx+=1\n",
        "  print(name)\n",
        "print(idx)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7MixYKzL-iZ"
      },
      "source": [
        "idx=0\n",
        "for name,param in  model.named_parameters():\n",
        "  if param.require_grad==True:\n",
        "    idx+=1\n",
        "    print(name)\n",
        "print(idx)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmtm5copKxUx"
      },
      "source": [
        "for i in  range(len(list(model.named_parameters()))):\n",
        "  print(list(model.named_parameters())[i])\n",
        "  print(list(model.parameters())[i])\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}